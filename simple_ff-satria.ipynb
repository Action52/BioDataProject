{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6HwIe3gAKWIy",
    "outputId": "a55c1a5d-f4b2-472d-ebee-f753e1fc5415"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0iopNSsqKebZ",
    "outputId": "ae0f0a09-7cac-4756-d927-4fc086a89b6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Uni/UniPD/BioData/project/biological_data_pfp\n"
     ]
    }
   ],
   "source": [
    "cd 'drive/MyDrive/Uni/UniPD/BioData/project/biological_data_pfp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "r8NK2V60KguN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 15:37:47.990527: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-26 15:37:47.990581: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-26 15:37:47.991473: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-26 15:37:47.997077: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-26 15:37:48.655713: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx\n",
    "import hashlib\n",
    "import obonet\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import sparse\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Hbjhqs_MKkM6"
   },
   "outputs": [],
   "source": [
    "def readh5_to_dict(file_path):\n",
    "  # Create an empty dictionary to store the data\n",
    "  p_embeddings_data = {}\n",
    "\n",
    "  # Open the HDF5 file\n",
    "  with h5py.File(file_path, 'r') as p_embeddings:\n",
    "    # Store the data in the dictionary\n",
    "    for key in p_embeddings.keys():\n",
    "      p_embeddings_data[key] = p_embeddings[key][...]\n",
    "\n",
    "  return p_embeddings_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RjTDFHv5K2j4"
   },
   "outputs": [],
   "source": [
    "def sample_protein_ids(file_path,percentage):\n",
    "\n",
    "  # Read the IDs from the text file\n",
    "  with open(file_path, 'r') as file:\n",
    "    ids = [line.strip() for line in file]\n",
    "\n",
    "  # Calculate the index to get the first 30% of IDs\n",
    "  split_index = int(len(ids) * percentage)\n",
    "\n",
    "  # Select the first 30% of IDs\n",
    "  selected_ids = ids[:split_index]\n",
    "\n",
    "  return selected_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Y1i9yPHqLdUh"
   },
   "outputs": [],
   "source": [
    "def read_tsv(tsv_file_path):\n",
    "  # Read the TSV file into a Pandas DataFrame\n",
    "  df_train_set = pd.read_csv(tsv_file_path, sep='\\t')\n",
    "\n",
    "  # Display the DataFrame\n",
    "  return df_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "62-TWs4OOTCJ"
   },
   "outputs": [],
   "source": [
    "def read_dat(file_path):\n",
    "  column_names = ['Protein_ID', 'IPR_ID', 'description', 'domain','dc1','dc2']\n",
    "  df = pd.read_csv(file_path, delimiter='\\t',names=column_names)\n",
    "\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "y71QKlmMMHuo"
   },
   "outputs": [],
   "source": [
    "def filter_train_data(df, selected_ids, category):\n",
    "  filtered_df = df[df['Protein_ID'].isin(selected_ids)]\n",
    "  filtered_df = filtered_df[filtered_df['aspect'] == category]\n",
    "\n",
    "  return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-HglxHVZN2dy"
   },
   "outputs": [],
   "source": [
    "def encode_go_terms(train_df):\n",
    "  one_hot_encoding = pd.get_dummies(train_df['GO_term'])\n",
    "\n",
    "  # Concatenate the one-hot encoded columns with the original DataFrame\n",
    "  df_encoded = pd.concat([train_df, one_hot_encoding], axis=1)\n",
    "  df_encoded_grouped = df_encoded.groupby('Protein_ID').sum().reset_index()\n",
    "\n",
    "  return df_encoded_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_go_terms_sparse(train_df, chunk_size=10000):\n",
    "    # Unique GO terms and Protein IDs\n",
    "    go_terms = train_df['GO_term'].unique()\n",
    "    protein_ids = train_df['Protein_ID'].unique()\n",
    "    \n",
    "    # Mapping of GO terms and Protein IDs to integer indices\n",
    "    go_term_to_index = {go_term: i for i, go_term in enumerate(go_terms)}\n",
    "    protein_id_to_index = {protein_id: i for i, protein_id in enumerate(protein_ids)}\n",
    "    \n",
    "    # Initialize a sparse matrix\n",
    "    encoded_matrix = sparse.lil_matrix((len(protein_ids), len(go_terms)), dtype=np.int8)\n",
    "    \n",
    "    # Process in chunks using tqdm for progress bar\n",
    "    total_rows = train_df.shape[0]\n",
    "    for start in tqdm(range(0, total_rows, chunk_size), desc=\"Encoding\", total=total_rows // chunk_size + 1):\n",
    "        end = min(start + chunk_size, total_rows)\n",
    "        chunk = train_df.iloc[start:end]\n",
    "        \n",
    "        rows = chunk['Protein_ID'].map(protein_id_to_index)\n",
    "        cols = chunk['GO_term'].map(go_term_to_index)\n",
    "        data = np.ones(len(chunk), dtype=np.int8)\n",
    "        \n",
    "        # Create a sparse matrix for the chunk\n",
    "        chunk_matrix = sparse.coo_matrix((data, (rows, cols)), shape=encoded_matrix.shape, dtype=np.int8)\n",
    "        \n",
    "        # Add the chunk matrix to the main matrix\n",
    "        encoded_matrix += chunk_matrix\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_encoded = pd.DataFrame.sparse.from_spmatrix(encoded_matrix, index=protein_ids, columns=go_terms)\n",
    "    df_encoded = df_encoded.reset_index()\n",
    "    df_encoded.rename(columns={'index': 'Protein_ID'}, inplace=True)\n",
    "\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VL4CJoenW_G6"
   },
   "outputs": [],
   "source": [
    "def encode_ipr_domain(df_ipr):\n",
    "    df_ipr = df_ipr.drop(columns=['IPR_ID', 'description','dc1','dc2'])\n",
    "    one_hot_encoding = pd.get_dummies(df_ipr['domain'],sparse=True)\n",
    "\n",
    "    # Concatenate the one-hot encoded columns with the original DataFrame\n",
    "    df_encoded = pd.concat([df_ipr, one_hot_encoding], axis=1)\n",
    "    df_encoded_grouped = df_encoded.groupby('Protein_ID').sum().reset_index()\n",
    "\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0hnJggsuL3XU"
   },
   "outputs": [],
   "source": [
    "def get_embeddings(df, embeddings_dict):\n",
    "  df['embedding'] = df['Protein_ID'].map(embeddings_dict)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mSuC-w8ITSSG"
   },
   "outputs": [],
   "source": [
    "def get_ipr(df_ipr,df_train):\n",
    "   isp_dict = df_ipr.set_index('Protein_ID')['domain'].to_dict()\n",
    "   df_train['ipr'] = df_train['Protein_ID'].map(isp_dict)\n",
    "\n",
    "   return df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "qcA4jvHAbkQp"
   },
   "outputs": [],
   "source": [
    "def create_y(df):\n",
    "  y = df.to_numpy()\n",
    "  return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Z2pra8kYb30E"
   },
   "outputs": [],
   "source": [
    "def create_X(df,variables):\n",
    "  X = np.array(df[variables])\n",
    "  X = np.vstack(X)\n",
    "\n",
    "  return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_freq(column, freq):\n",
    "    top_freq = []\n",
    "    for col in column:\n",
    "        if col not in freq:\n",
    "            continue\n",
    "        top_freq.append(col)\n",
    "    return top_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_ids(selected_ids, train_ids, percentage):\n",
    "    ids = sample_protein_ids(train_ids, percentage)\n",
    "    new_ids = sample_protein_ids(selected_ids, 1.0)\n",
    "    difference = list(set(ids) - set(new_ids))\n",
    "    return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_data(test_embeddings_data, test_ids):\n",
    "    X_test = []\n",
    "    for id in test_ids:\n",
    "        X_test.append(test_embeddings_data[id])\n",
    "    X_test = np.array(X_test)\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred):\n",
    "    precision = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) / (K.sum(K.round(K.clip(y_pred, 0, 1))) + K.epsilon())\n",
    "    recall = K.sum(K.round(K.clip(y_true * y_pred, 0, 1))) / (K.sum(K.round(K.clip(y_true, 0, 1))) + K.epsilon())\n",
    "    return 2 * (precision * recall) / (precision + recall + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cv(X, y, model, n_splits):\n",
    "    histories = []\n",
    "    \n",
    "    # Initialize KFold\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Iterate over each fold\n",
    "    fold_no = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # Splitting the data into training and testing sets for this fold\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "        # Fit the model\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "        history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "        histories.append(history)\n",
    "        \n",
    "        # Here, you can evaluate the model on the test set, e.g., calculate metrics\n",
    "        results = model.evaluate(X_test, y_test)\n",
    "        print(f\"Test results - Fold {fold_no}: {model.metrics_names[0]} of {results[0]}; {model.metrics_names[1]} of {results[1]*100}%\")\n",
    "    \n",
    "        fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Propagating the probability of the children to the parent, in this case if the parent has several children, we will take the max probabilty of the children\n",
    "def post_processing(y_pred, pred_scolumns, graph):\n",
    "    new_preds = []\n",
    "\n",
    "    for pred in y_pred:\n",
    "        ### Build prediction dict\n",
    "        preds = {k: 0 for k in pred_columns}\n",
    "        new_pred = [0 for i in range(len(pred))]\n",
    "        for i in range(len(pred)):\n",
    "            term = pred_columns[i]\n",
    "            preds[term] = pred[i]\n",
    "\n",
    "        ### Search the probabilty for the parent\n",
    "        pool = set()\n",
    "        for term, prob in preds.items():\n",
    "            for parent, child, key in graph.in_edges(term, keys=True):\n",
    "                if key not in {'is_a', 'part_of'} or parent not in preds:\n",
    "                    continue\n",
    "\n",
    "                probability = max(prob, preds[parent])\n",
    "                preds[parent] = probability\n",
    "                    \n",
    "        ### Build the array for the new preds\n",
    "        for term, prob in preds.items():\n",
    "            idx = pred_columns.index(term)\n",
    "            new_pred[idx] = prob\n",
    "        new_preds.append(new_pred)\n",
    "    return np.array(new_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_submission_df(y_pred, test_ids, pred_columns):\n",
    "    # assert that the length of y_pred must be same as test_ids\n",
    "    assert len(y_pred) == len(test_ids)\n",
    "    \n",
    "    # Group by the result and then sort by score id\n",
    "    out = {'id': [], 'term': [], 'score': []}\n",
    "    for i in range(len(y_pred)):\n",
    "        for j in range(len(y_pred[i])):\n",
    "            out['id'].append(test_ids[i])\n",
    "            out['term'].append(pred_columns[j])\n",
    "            out['score'].append(y_pred[i][j])\n",
    "    \n",
    "    out_df = pd.DataFrame(out).reset_index(drop=True)\n",
    "    \n",
    "    out_df = out_df.groupby('id', group_keys=False)\n",
    "    out_df = out_df.apply(lambda x: x.sort_values(by='score', ascending=False))\n",
    "    \n",
    "    # Filter the DataFrame\n",
    "    out_df = out_df[out_df['id'].isin(test_ids)]\n",
    "    \n",
    "    # Convert the 'ID' column to a Categorical with the order defined in filter_array\n",
    "    out_df['id'] = pd.Categorical(out_df['id'], categories=test_ids, ordered=True)\n",
    "    \n",
    "    # Sort by the 'ID' column\n",
    "    out_df = out_df.sort_values('id')\n",
    "    out_df['id'] = out_df['id'].astype(str)\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train):\n",
    "    '''\n",
    "        Train the model.\n",
    "    '''\n",
    "    embedding_size = len(X_train[1]) \n",
    "    num_classes = len(y_train[1])\n",
    "    \n",
    "    final_model = keras.Sequential([\n",
    "        layers.Input(shape=(embedding_size,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    final_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[f1_score])\n",
    "    final_model.fit(X_train, y_train, epochs=50, batch_size=32)\n",
    "\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_predictions(bp_path, mf_path, cc_path):\n",
    "    # Read the files into DataFrames\n",
    "    bp_df = pd.read_csv(bp, sep='\\t', header=None, names=['Protein_ID', 'GO_term', 'score'])\n",
    "    mf_df = pd.read_csv(mf, sep='\\t', header=None, names=['Protein_ID', 'GO_term', 'score'])\n",
    "    cc_df = pd.read_csv(cc, sep='\\t', header=None, names=['Protein_ID', 'GO_term', 'score'])\n",
    "    \n",
    "    # Concatenate the DataFrames\n",
    "    concatenated_df = pd.concat([bp_df, mf_df, cc_df])\n",
    "    \n",
    "    # Create a custom sorting order based on the external list\n",
    "    sorting_order = {id: index for index, id in enumerate(test_ids)}\n",
    "    concatenated_df['sort_order'] = concatenated_df['Protein_ID'].map(sorting_order)\n",
    "    \n",
    "    # Sort by custom order and then by probability within each group\n",
    "    sorted_df = concatenated_df.sort_values(by=['sort_order', 'score'], ascending=[True, False])\n",
    "    \n",
    "    # Limit to 1500 rows per ID\n",
    "    limited_df = sorted_df.groupby('Protein_ID').head(1500)\n",
    "    \n",
    "    # Drop the auxiliary 'sort_order' column\n",
    "    limited_df = limited_df.drop(columns=['sort_order'])\n",
    "    \n",
    "    return limited_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Dataset - Combined Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set_all = read_tsv('./dataset/train/train_set.tsv')\n",
    "# Desired aspects\n",
    "desired_aspects = {'cellular_component', 'biological_process', 'molecular_function'}\n",
    "\n",
    "# Function to check if all aspects are present\n",
    "def check_aspects(group):\n",
    "    return desired_aspects == set(group['aspect'])\n",
    "\n",
    "# Apply the function to each group\n",
    "result = df_train_set_all.groupby('Protein_ID').filter(check_aspects)['Protein_ID'].unique()\n",
    "np.savetxt('./dataset/train/sampled_train.txt', result, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataset containing 1000 data of the proteins in the result, this is created to help validate our modell using cafa evaluator\n",
    "selected_test_ids = np.array(sample_protein_ids('./dataset/train/sampled_train.txt', 0.03140))\n",
    "np.savetxt('./dataset/test/sampled_test.txt', selected_test_ids, fmt='%s')\n",
    "\n",
    "# Create ground truth file\n",
    "ground_truth_df = df_train_set_all[df_train_set_all['Protein_ID'].isin(selected_test_ids)]\n",
    "ground_truth_df = ground_truth_df[['Protein_ID', 'GO_term']]\n",
    "ground_truth_df.to_csv('./dataset/test/sampled_gt.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_embeddings_data = readh5_to_dict('./dataset/train/train_embeddings.h5')\n",
    "test_embeddings_data = readh5_to_dict('./dataset/test/test_embeddings.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.86 s, sys: 44 ms, total: 3.9 s\n",
      "Wall time: 3.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "graph = obonet.read_obo('./dataset/taxonomy/go-basic.obo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Dataset - Celullar component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "uxHe-ugrM2m1"
   },
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "selected_ids = create_training_ids('./dataset/test/sampled_test.txt', './dataset/train/train_ids.txt', 1.0)\n",
    "df_train_set = filter_train_data(df_train_set_all, selected_ids,'cellular_component')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "test_ids = sample_protein_ids('./dataset/test/sampled_test.txt', 1.0)\n",
    "X_test_gt = build_test_data(p_embeddings_data, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "id": "d0Y7tqbPNgU2",
    "outputId": "680b45a5-a649-454f-a1df-a8ba2f6702e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|███████████████████████████████| 110/110 [00:43<00:00,  2.53it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_ID</th>\n",
       "      <th>GO:0005575</th>\n",
       "      <th>GO:0110165</th>\n",
       "      <th>GO:0005622</th>\n",
       "      <th>GO:0043226</th>\n",
       "      <th>GO:0030139</th>\n",
       "      <th>GO:0097708</th>\n",
       "      <th>GO:0005737</th>\n",
       "      <th>GO:0045335</th>\n",
       "      <th>GO:0031982</th>\n",
       "      <th>...</th>\n",
       "      <th>GO:0005637</th>\n",
       "      <th>GO:0099092</th>\n",
       "      <th>GO:0099091</th>\n",
       "      <th>GO:0030140</th>\n",
       "      <th>GO:0005703</th>\n",
       "      <th>GO:0097386</th>\n",
       "      <th>GO:0000235</th>\n",
       "      <th>GO:0070822</th>\n",
       "      <th>GO:0010287</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q55DL5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1418, 0.06207, 0.07367, -0.0712, 0.0703, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O81027</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0491, 0.0389, -0.0178, 0.02779, -0.00568, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q04418</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.022, -0.06964, -0.007042, 0.0544, -0.04633...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q7ZT12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.04028, -0.03357, 0.1046, 0.0669, -0.07935, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q07627</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.013565, 0.1422, 0.1249, 0.05283, 0.00569, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protein_ID  GO:0005575  GO:0110165  GO:0005622  GO:0043226  GO:0030139  \\\n",
       "0     Q55DL5           1           1           1           1           1   \n",
       "1     O81027           1           1           1           1           0   \n",
       "2     Q04418           1           1           1           0           0   \n",
       "3     Q7ZT12           1           1           0           0           0   \n",
       "4     Q07627           1           1           1           0           0   \n",
       "\n",
       "   GO:0097708  GO:0005737  GO:0045335  GO:0031982  ...  GO:0005637  \\\n",
       "0           1           1           1           1  ...           0   \n",
       "1           0           1           0           0  ...           0   \n",
       "2           0           1           0           0  ...           0   \n",
       "3           0           0           0           0  ...           0   \n",
       "4           0           1           0           0  ...           0   \n",
       "\n",
       "   GO:0099092  GO:0099091  GO:0030140  GO:0005703  GO:0097386  GO:0000235  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   GO:0070822  GO:0010287                                          embedding  \n",
       "0           0           0  [0.1418, 0.06207, 0.07367, -0.0712, 0.0703, -0...  \n",
       "1           0           0  [0.0491, 0.0389, -0.0178, 0.02779, -0.00568, 0...  \n",
       "2           0           0  [-0.022, -0.06964, -0.007042, 0.0544, -0.04633...  \n",
       "3           0           0  [0.04028, -0.03357, 0.1046, 0.0669, -0.07935, ...  \n",
       "4           0           0  [0.013565, 0.1422, 0.1249, 0.05283, 0.00569, -...  \n",
       "\n",
       "[5 rows x 680 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded = encode_go_terms_sparse(df_train_set)\n",
    "df_encoded = get_embeddings(df_encoded, p_embeddings_data)\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aKNV2HygPBYy",
    "outputId": "67a2bf91-619a-41c0-b74e-7a0ddac93a29"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15083/2827862180.py:1: FutureWarning: Allowing arbitrary scalar fill_value in SparseDtype is deprecated. In a future version, the fill_value must be a valid value for the SparseDtype.subtype.\n",
      "  df_encoded.isna().sum().sum()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oUyI1vNNkK_G",
    "outputId": "9e144400-cc28-4744-9115-1e4c0a0c965e"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_encoded\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[43mdf_encoded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1147\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1150\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1654\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1652\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n\u001b[1;32m   1653\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[0;32m-> 1654\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_lowerdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1039\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tup):\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_label_like(key):\n\u001b[1;32m   1037\u001b[0m         \u001b[38;5;66;03m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m         \u001b[38;5;66;03m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[0;32m-> 1039\u001b[0m         section \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1041\u001b[0m         \u001b[38;5;66;03m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m         \u001b[38;5;66;03m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m         \u001b[38;5;66;03m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m section\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m   1045\u001b[0m             \u001b[38;5;66;03m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m             \u001b[38;5;66;03m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/indexing.py:1716\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1713\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m   1714\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m-> 1716\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/frame.py:3789\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3787\u001b[0m \u001b[38;5;66;03m# irow\u001b[39;00m\n\u001b[1;32m   3788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3789\u001b[0m     new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_xs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m     \u001b[38;5;66;03m# if we are a copy, mark as such\u001b[39;00m\n\u001b[1;32m   3792\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(new_mgr\u001b[38;5;241m.\u001b[39marray, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m new_mgr\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:985\u001b[0m, in \u001b[0;36mBlockManager.fast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mconstruct_array_type()\n\u001b[0;32m--> 985\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(result)))\n\u001b[1;32m    988\u001b[0m block \u001b[38;5;241m=\u001b[39m new_block(result, placement\u001b[38;5;241m=\u001b[39mbp, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/arrays/sparse/array.py:587\u001b[0m, in \u001b[0;36mSparseArray._from_sequence\u001b[0;34m(cls, scalars, dtype, copy)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_sequence\u001b[39m(\u001b[38;5;28mcls\u001b[39m, scalars, \u001b[38;5;241m*\u001b[39m, dtype: Dtype \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 587\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mscalars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/arrays/sparse/array.py:474\u001b[0m, in \u001b[0;36mSparseArray.__init__\u001b[0;34m(self, data, sparse_index, fill_value, kind, dtype, copy)\u001b[0m\n\u001b[1;32m    472\u001b[0m                 fill_value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime64(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    473\u001b[0m         data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data)\n\u001b[0;32m--> 474\u001b[0m     sparse_values, sparse_index, fill_value \u001b[38;5;241m=\u001b[39m \u001b[43m_make_sparse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument \"dtype\" to \"_make_sparse\" has incompatible type\u001b[39;49;00m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# \"Union[ExtensionDtype, dtype[Any], None]\"; expected\u001b[39;49;00m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# \"Optional[dtype[Any]]\"\u001b[39;49;00m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;66;03m# error: Argument \"dtype\" to \"asarray\" has incompatible type\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionDtype, dtype[Any], None]\"; expected \"None\"\u001b[39;00m\n\u001b[1;32m    486\u001b[0m     sparse_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data, dtype\u001b[38;5;241m=\u001b[39mdtype)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/arrays/sparse/array.py:1867\u001b[0m, in \u001b[0;36m_make_sparse\u001b[0;34m(arr, kind, fill_value, dtype)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m   1863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   1864\u001b[0m     \u001b[38;5;66;03m# element-wise equality check method in numpy doesn't treat\u001b[39;00m\n\u001b[1;32m   1865\u001b[0m     \u001b[38;5;66;03m# each element type, eg. 0, 0.0, and False are treated as\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m     \u001b[38;5;66;03m# same. So we have to check the both of its type and value.\u001b[39;00m\n\u001b[0;32m-> 1867\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43msplib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_mask_object_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1869\u001b[0m     mask \u001b[38;5;241m=\u001b[39m arr \u001b[38;5;241m!=\u001b[39m fill_value\n",
      "File \u001b[0;32msparse.pyx:729\u001b[0m, in \u001b[0;36mpandas._libs.sparse.make_mask_object_ndarray\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "df_encoded.columns[3:-1][df_encoded.iloc[1,3:-1] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top N labels, for celullar component we select top 300\n",
    "freq_df = pd.read_csv('./dataset/train/cellular_component_freq.csv')[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Ru3RD7uTbfVi"
   },
   "outputs": [],
   "source": [
    "y_columns = df_encoded.iloc[:, 3:-1]\n",
    "pred_columns = get_top_freq(y_columns.columns.tolist(), set(freq_df['id']))\n",
    "\n",
    "y_columns = y_columns[pred_columns]\n",
    "y = create_y(y_columns)\n",
    "X = create_X(df_encoded,'embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_B42EKPecoCD",
    "outputId": "d617883a-e559-4423-e96d-3c8fe35b9a31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2222/2222 [==============================] - 3s 1ms/step - loss: 0.0875 - f1_score: 0.6186\n",
      "Epoch 2/10\n",
      "2222/2222 [==============================] - 3s 1ms/step - loss: 0.0707 - f1_score: 0.6583\n",
      "Epoch 3/10\n",
      "2222/2222 [==============================] - 3s 1ms/step - loss: 0.0680 - f1_score: 0.6691\n",
      "Epoch 4/10\n",
      "2222/2222 [==============================] - 3s 1ms/step - loss: 0.0662 - f1_score: 0.6765\n",
      "Epoch 5/10\n",
      "2222/2222 [==============================] - 3s 1ms/step - loss: 0.0649 - f1_score: 0.6826\n",
      "Epoch 6/10\n",
      "2222/2222 [==============================] - 3s 1ms/step - loss: 0.0637 - f1_score: 0.6874\n",
      "Epoch 7/10\n",
      "2222/2222 [==============================] - 3s 1ms/step - loss: 0.0627 - f1_score: 0.6923\n",
      "Epoch 8/10\n",
      "2222/2222 [==============================] - 3s 1ms/step - loss: 0.0619 - f1_score: 0.6957\n",
      "Epoch 9/10\n",
      "2222/2222 [==============================] - 3s 1ms/step - loss: 0.0610 - f1_score: 0.6998\n",
      "Epoch 10/10\n",
      "2222/2222 [==============================] - 3s 1ms/step - loss: 0.0603 - f1_score: 0.7035\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "model = train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lnDbWCBVcv7X",
    "outputId": "9f95b107-7edf-49fa-8576-4e48c7d55549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/393 [==============================] - 0s 685us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Processing - Cellular Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_pred = post_processing(y_pred, pred_columns, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation - Cellular Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.06      0.11        52\n",
      "           1       0.57      0.12      0.20       109\n",
      "           2       0.67      0.07      0.13        81\n",
      "           3       0.25      0.03      0.05       109\n",
      "           4       0.60      0.46      0.52        65\n",
      "           5       0.55      0.06      0.10       104\n",
      "           6       0.62      0.08      0.15       274\n",
      "           7       0.50      0.06      0.11       101\n",
      "           8       0.33      0.02      0.04       108\n",
      "           9       0.40      0.05      0.08        44\n",
      "          10       0.67      0.38      0.49        52\n",
      "          11       0.85      0.66      0.74        50\n",
      "          12       0.71      0.05      0.10        96\n",
      "          13       0.40      0.03      0.06        63\n",
      "          14       0.33      0.01      0.03        68\n",
      "          15       0.00      0.00      0.00        37\n",
      "          16       0.83      0.17      0.28       294\n",
      "          17       0.00      0.00      0.00        29\n",
      "          18       0.55      0.05      0.09       117\n",
      "          19       0.00      0.00      0.00        36\n",
      "          20       0.00      0.00      0.00        53\n",
      "          21       1.00      1.00      1.00     12546\n",
      "          22       0.74      0.34      0.47      1016\n",
      "          23       0.73      0.30      0.43       772\n",
      "          24       0.57      0.47      0.52       246\n",
      "          25       0.91      0.93      0.92      9938\n",
      "          26       0.83      0.65      0.73      4005\n",
      "          27       0.79      0.11      0.19       218\n",
      "          28       0.54      0.17      0.26        41\n",
      "          29       0.68      0.43      0.53      1578\n",
      "          30       0.29      0.03      0.05       136\n",
      "          31       0.55      0.22      0.31        82\n",
      "          32       0.69      0.22      0.33       536\n",
      "          33       0.00      0.00      0.00        40\n",
      "          34       0.71      0.16      0.27       451\n",
      "          35       0.79      0.83      0.81      7519\n",
      "          36       0.81      0.61      0.69      1286\n",
      "          37       0.55      0.22      0.32       288\n",
      "          38       0.60      0.04      0.08        71\n",
      "          39       0.55      0.26      0.35       183\n",
      "          40       0.67      0.36      0.47        50\n",
      "          41       0.57      0.32      0.41       155\n",
      "          42       0.60      0.49      0.54        65\n",
      "          43       0.63      0.14      0.23       172\n",
      "          44       1.00      0.13      0.22        87\n",
      "          45       0.46      0.07      0.12       331\n",
      "          46       0.00      0.00      0.00        96\n",
      "          47       1.00      0.03      0.07        86\n",
      "          48       0.64      0.13      0.22       443\n",
      "          49       0.57      0.14      0.22       179\n",
      "          50       0.88      0.05      0.09       148\n",
      "          51       0.76      0.32      0.45       797\n",
      "          52       0.00      0.00      0.00        65\n",
      "          53       0.58      0.12      0.20       235\n",
      "          54       0.69      0.23      0.35       580\n",
      "          55       0.55      0.17      0.26        64\n",
      "          56       0.64      0.07      0.13        97\n",
      "          57       0.73      0.16      0.26        50\n",
      "          58       0.75      0.07      0.13       163\n",
      "          59       0.57      0.16      0.25       281\n",
      "          60       0.83      0.11      0.19        46\n",
      "          61       1.00      0.01      0.01       138\n",
      "          62       0.63      0.28      0.39      2605\n",
      "          63       0.83      0.41      0.54       209\n",
      "          64       0.68      0.28      0.39       780\n",
      "          65       0.62      0.08      0.14        98\n",
      "          66       0.00      0.00      0.00        43\n",
      "          67       1.00      0.03      0.05        38\n",
      "          68       0.70      0.62      0.66      2323\n",
      "          69       0.56      0.06      0.11       287\n",
      "          70       0.50      0.05      0.09        41\n",
      "          71       1.00      0.02      0.04        89\n",
      "          72       0.59      0.28      0.38       390\n",
      "          73       0.62      0.21      0.32        75\n",
      "          74       0.50      0.03      0.05        35\n",
      "          75       0.77      0.05      0.09       204\n",
      "          76       0.50      0.01      0.03        75\n",
      "          77       0.50      0.45      0.47       130\n",
      "          78       0.75      0.67      0.71        49\n",
      "          79       0.47      0.12      0.20        56\n",
      "          80       0.67      0.01      0.03       146\n",
      "          81       0.86      0.68      0.76       313\n",
      "          82       0.71      0.53      0.61       123\n",
      "          83       0.51      0.52      0.51        83\n",
      "          84       0.79      0.32      0.45        69\n",
      "          85       0.62      0.29      0.39        52\n",
      "          86       0.90      0.62      0.74       477\n",
      "          87       0.50      0.50      0.50        82\n",
      "          88       0.85      0.39      0.53        88\n",
      "          89       0.50      0.03      0.06        92\n",
      "          90       0.00      0.00      0.00        46\n",
      "          91       0.27      0.05      0.08        66\n",
      "          92       0.57      0.30      0.40        79\n",
      "          93       0.37      0.05      0.08       217\n",
      "          94       1.00      0.03      0.06        95\n",
      "          95       0.50      0.02      0.05        41\n",
      "          96       0.72      0.39      0.50      1865\n",
      "          97       0.64      0.05      0.10       255\n",
      "          98       0.00      0.00      0.00        83\n",
      "          99       0.75      0.08      0.14       187\n",
      "         100       0.64      0.26      0.37       498\n",
      "         101       0.65      0.32      0.43       109\n",
      "         102       0.70      0.09      0.16        76\n",
      "         103       0.68      0.64      0.66      3504\n",
      "         104       0.17      0.02      0.03        55\n",
      "         105       0.50      0.06      0.11       118\n",
      "         106       0.67      0.23      0.34        35\n",
      "         107       1.00      0.01      0.02       239\n",
      "         108       1.00      0.01      0.02       108\n",
      "         109       0.74      0.53      0.62       116\n",
      "         110       0.56      0.23      0.33       200\n",
      "         111       0.73      0.19      0.30       167\n",
      "         112       0.00      0.00      0.00        55\n",
      "         113       0.92      0.32      0.47        73\n",
      "         114       0.90      0.34      0.49       136\n",
      "         115       0.91      0.20      0.33        49\n",
      "         116       0.65      0.24      0.35        92\n",
      "         117       0.78      0.17      0.28        82\n",
      "         118       1.00      0.11      0.20        37\n",
      "         119       0.61      0.22      0.33       867\n",
      "         120       0.67      0.04      0.08       100\n",
      "         121       0.00      0.00      0.00       113\n",
      "         122       0.50      0.04      0.07        83\n",
      "         123       1.00      0.04      0.08        51\n",
      "         124       0.50      0.04      0.08       142\n",
      "         125       0.00      0.00      0.00       195\n",
      "         126       0.53      0.47      0.50       514\n",
      "         127       0.78      0.75      0.76        56\n",
      "         128       0.00      0.00      0.00       236\n",
      "         129       0.00      0.00      0.00       171\n",
      "         130       0.00      0.00      0.00        58\n",
      "         131       0.78      0.06      0.11       123\n",
      "         132       0.68      0.37      0.48        57\n",
      "         133       0.00      0.00      0.00        43\n",
      "         134       0.00      0.00      0.00        57\n",
      "         135       0.58      0.06      0.10       247\n",
      "         136       1.00      0.02      0.05        41\n",
      "         137       0.50      0.07      0.12        44\n",
      "         138       0.00      0.00      0.00        69\n",
      "         139       0.50      0.10      0.17        30\n",
      "         140       0.56      0.07      0.13        70\n",
      "         141       0.67      0.08      0.15        49\n",
      "         142       0.67      0.38      0.49        52\n",
      "         143       0.67      0.21      0.32        47\n",
      "         144       0.48      0.33      0.39       244\n",
      "         145       0.57      0.18      0.27      1137\n",
      "         146       1.00      0.09      0.16        56\n",
      "         147       1.00      0.01      0.02       106\n",
      "         148       0.00      0.00      0.00        80\n",
      "         149       0.55      0.15      0.24       782\n",
      "         150       0.60      0.07      0.13        40\n",
      "         151       0.43      0.05      0.09        60\n",
      "         152       0.00      0.00      0.00        57\n",
      "         153       1.00      0.14      0.25        42\n",
      "         154       0.60      0.03      0.06        88\n",
      "         155       0.55      0.25      0.34       265\n",
      "         156       0.64      0.22      0.33       624\n",
      "         157       0.64      0.12      0.20       137\n",
      "         158       0.69      0.41      0.51      2304\n",
      "         159       0.64      0.24      0.35       680\n",
      "         160       0.78      0.30      0.43        71\n",
      "         161       0.69      0.47      0.56      1980\n",
      "         162       0.54      0.15      0.23      1065\n",
      "         163       0.00      0.00      0.00        56\n",
      "         164       0.49      0.11      0.18       374\n",
      "         165       0.56      0.27      0.37        55\n",
      "         166       0.86      0.06      0.10       108\n",
      "         167       0.00      0.00      0.00        84\n",
      "         168       0.55      0.19      0.28       160\n",
      "         169       0.62      0.35      0.45      2335\n",
      "         170       0.81      0.17      0.28       337\n",
      "         171       0.76      0.54      0.63       113\n",
      "         172       0.66      0.38      0.48        72\n",
      "         173       0.83      0.34      0.48        44\n",
      "         174       0.67      0.35      0.46        62\n",
      "         175       0.00      0.00      0.00        58\n",
      "         176       0.58      0.22      0.31        65\n",
      "         177       0.00      0.00      0.00        43\n",
      "         178       0.00      0.00      0.00        56\n",
      "         179       0.58      0.06      0.12       109\n",
      "         180       0.42      0.09      0.14        57\n",
      "         181       0.00      0.00      0.00        34\n",
      "         182       0.33      0.03      0.05       103\n",
      "         183       0.00      0.00      0.00       298\n",
      "         184       0.63      0.34      0.44        77\n",
      "         185       0.57      0.12      0.20       246\n",
      "         186       0.00      0.00      0.00        39\n",
      "         187       0.67      0.04      0.08       149\n",
      "         188       0.86      0.43      0.57        42\n",
      "         189       0.66      0.32      0.43        59\n",
      "         190       0.00      0.00      0.00        47\n",
      "         191       0.63      0.13      0.22       926\n",
      "         192       0.33      0.01      0.01       413\n",
      "         193       0.00      0.00      0.00       200\n",
      "         194       0.00      0.00      0.00        37\n",
      "         195       0.00      0.00      0.00        36\n",
      "         196       0.84      0.86      0.85      8546\n",
      "         197       0.81      0.81      0.81      7822\n",
      "         198       0.70      0.33      0.45      2186\n",
      "         199       0.83      0.85      0.84      8183\n",
      "         200       0.00      0.00      0.00       356\n",
      "         201       0.82      0.80      0.81      7394\n",
      "         202       0.70      0.34      0.45      2182\n",
      "         203       0.69      0.41      0.51      2304\n",
      "         204       0.75      0.26      0.39        92\n",
      "         205       0.63      0.24      0.35       113\n",
      "         206       0.40      0.05      0.09        39\n",
      "         207       0.66      0.38      0.48        72\n",
      "         208       0.75      0.54      0.63       114\n",
      "         209       0.00      0.00      0.00        58\n",
      "         210       0.00      0.00      0.00       218\n",
      "         211       0.00      0.00      0.00        61\n",
      "         212       0.00      0.00      0.00        37\n",
      "         213       0.81      0.48      0.60       184\n",
      "         214       0.00      0.00      0.00        66\n",
      "         215       0.11      0.01      0.01       172\n",
      "         216       0.08      0.01      0.02        77\n",
      "         217       0.76      0.07      0.13       450\n",
      "         218       0.25      0.01      0.03        69\n",
      "         219       0.17      0.01      0.02        93\n",
      "         220       0.00      0.00      0.00       166\n",
      "         221       0.50      0.08      0.14        89\n",
      "         222       0.71      0.33      0.45        45\n",
      "         223       0.68      0.31      0.42        55\n",
      "         224       0.00      0.00      0.00        49\n",
      "         225       1.00      0.01      0.01       146\n",
      "         226       0.55      0.06      0.11        94\n",
      "         227       0.00      0.00      0.00        56\n",
      "         228       0.54      0.25      0.35       130\n",
      "         229       0.63      0.41      0.50       131\n",
      "         230       0.44      0.06      0.10        70\n",
      "         231       0.50      0.06      0.10        70\n",
      "         232       0.00      0.00      0.00       356\n",
      "         233       0.69      0.41      0.51      2304\n",
      "         234       0.00      0.00      0.00       326\n",
      "         235       0.50      0.07      0.12        30\n",
      "         236       0.58      0.10      0.17       389\n",
      "         237       0.50      0.01      0.02        82\n",
      "         238       0.54      0.31      0.39        65\n",
      "         239       0.50      0.15      0.23        40\n",
      "         240       0.44      0.19      0.26        43\n",
      "         241       0.62      0.12      0.20        41\n",
      "         242       0.68      0.66      0.67      2881\n",
      "         243       0.00      0.00      0.00        67\n",
      "         244       0.38      0.04      0.08        67\n",
      "         245       0.52      0.21      0.30       155\n",
      "         246       0.50      0.02      0.03       112\n",
      "         247       0.00      0.00      0.00       171\n",
      "         248       0.55      0.16      0.24       784\n",
      "         249       0.00      0.00      0.00        40\n",
      "         250       0.33      0.02      0.03        56\n",
      "         251       0.50      0.02      0.04       157\n",
      "         252       0.00      0.00      0.00        61\n",
      "         253       0.59      0.10      0.18       652\n",
      "         254       0.51      0.07      0.12       387\n",
      "         255       0.71      0.03      0.06       149\n",
      "         256       0.61      0.12      0.20       139\n",
      "         257       0.53      0.04      0.08       198\n",
      "         258       0.50      0.01      0.01       175\n",
      "         259       0.56      0.14      0.22       457\n",
      "         260       0.70      0.10      0.17       192\n",
      "         261       0.60      0.41      0.48       160\n",
      "         262       0.65      0.31      0.42        72\n",
      "         263       0.73      0.36      0.48        61\n",
      "         264       0.56      0.31      0.40        64\n",
      "         265       0.58      0.13      0.22       242\n",
      "         266       0.94      0.11      0.20       131\n",
      "         267       0.00      0.00      0.00        66\n",
      "         268       0.00      0.00      0.00        74\n",
      "         269       0.00      0.00      0.00        48\n",
      "         270       0.00      0.00      0.00       126\n",
      "         271       0.00      0.00      0.00        87\n",
      "         272       0.65      0.13      0.22       432\n",
      "         273       0.63      0.17      0.26       271\n",
      "         274       0.00      0.00      0.00       286\n",
      "         275       0.67      0.15      0.24       269\n",
      "         276       0.71      0.03      0.06       150\n",
      "         277       0.55      0.12      0.20       210\n",
      "         278       0.00      0.00      0.00       103\n",
      "         279       0.00      0.00      0.00        50\n",
      "         280       0.99      1.00      1.00     12439\n",
      "         281       0.63      0.13      0.22       912\n",
      "         282       0.71      0.11      0.20        44\n",
      "         283       0.54      0.33      0.41       523\n",
      "         284       0.33      0.04      0.07        52\n",
      "         285       0.62      0.20      0.30       382\n",
      "         286       0.00      0.00      0.00       111\n",
      "         287       1.00      0.07      0.13        57\n",
      "         288       0.61      0.24      0.34       805\n",
      "         289       0.53      0.17      0.26       145\n",
      "         290       0.75      0.06      0.12        48\n",
      "         291       0.50      0.11      0.17        57\n",
      "         292       0.00      0.00      0.00       343\n",
      "         293       0.44      0.05      0.10        74\n",
      "         294       0.82      0.39      0.53        84\n",
      "         295       0.85      0.61      0.71        56\n",
      "         296       0.54      0.13      0.21        99\n",
      "         297       0.59      0.23      0.33       339\n",
      "         298       0.55      0.19      0.28       152\n",
      "         299       0.79      0.33      0.47       384\n",
      "\n",
      "   micro avg       0.82      0.59      0.68    157757\n",
      "   macro avg       0.52      0.18      0.23    157757\n",
      "weighted avg       0.75      0.59      0.62    157757\n",
      " samples avg       0.83      0.66      0.70    157757\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satria/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Convert probabilities to binary predictions\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satria/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.56      0.51        52\n",
      "           1       0.01      0.94      0.02       109\n",
      "           2       0.01      1.00      0.01        81\n",
      "           3       0.03      0.90      0.06       109\n",
      "           4       0.01      0.97      0.01        65\n",
      "           5       0.01      0.86      0.02       104\n",
      "           6       0.02      0.86      0.04       274\n",
      "           7       0.16      0.07      0.10       101\n",
      "           8       0.01      0.98      0.02       108\n",
      "           9       0.00      0.98      0.01        44\n",
      "          10       0.67      0.38      0.49        52\n",
      "          11       0.00      1.00      0.01        50\n",
      "          12       0.13      0.23      0.17        96\n",
      "          13       0.01      1.00      0.01        63\n",
      "          14       0.55      0.09      0.15        68\n",
      "          15       0.04      0.19      0.07        37\n",
      "          16       0.02      1.00      0.05       294\n",
      "          17       0.02      0.03      0.02        29\n",
      "          18       0.15      0.22      0.18       117\n",
      "          19       0.00      1.00      0.01        36\n",
      "          20       0.00      1.00      0.01        53\n",
      "          21       1.00      1.00      1.00     12546\n",
      "          22       0.08      1.00      0.15      1016\n",
      "          23       0.06      1.00      0.12       772\n",
      "          24       0.29      0.57      0.39       246\n",
      "          25       0.79      1.00      0.88      9938\n",
      "          26       0.38      0.98      0.55      4005\n",
      "          27       0.03      0.60      0.06       218\n",
      "          28       0.00      1.00      0.01        41\n",
      "          29       0.13      1.00      0.22      1578\n",
      "          30       0.01      1.00      0.02       136\n",
      "          31       0.01      1.00      0.01        82\n",
      "          32       0.05      1.00      0.10       536\n",
      "          33       0.06      0.25      0.10        40\n",
      "          34       0.04      0.98      0.08       451\n",
      "          35       0.60      1.00      0.75      7519\n",
      "          36       0.12      0.98      0.22      1286\n",
      "          37       0.03      0.98      0.05       288\n",
      "          38       0.01      1.00      0.01        71\n",
      "          39       0.02      1.00      0.03       183\n",
      "          40       0.01      0.76      0.02        50\n",
      "          41       0.01      0.99      0.03       155\n",
      "          42       0.01      0.98      0.01        65\n",
      "          43       0.52      0.16      0.24       172\n",
      "          44       0.01      0.83      0.01        87\n",
      "          45       0.03      0.83      0.05       331\n",
      "          46       0.10      0.05      0.07        96\n",
      "          47       0.19      0.10      0.13        86\n",
      "          48       0.04      0.91      0.07       443\n",
      "          49       0.02      0.99      0.03       179\n",
      "          50       0.01      0.99      0.03       148\n",
      "          51       0.07      0.90      0.13       797\n",
      "          52       0.00      0.71      0.01        65\n",
      "          53       0.02      0.99      0.04       235\n",
      "          54       0.05      0.91      0.10       580\n",
      "          55       0.01      1.00      0.01        64\n",
      "          56       0.01      0.92      0.02        97\n",
      "          57       0.00      1.00      0.01        50\n",
      "          58       0.35      0.17      0.23       163\n",
      "          59       0.02      1.00      0.04       281\n",
      "          60       0.07      0.13      0.09        46\n",
      "          61       0.01      0.99      0.03       138\n",
      "          62       0.21      1.00      0.34      2605\n",
      "          63       0.02      0.97      0.04       209\n",
      "          64       0.07      0.97      0.14       780\n",
      "          65       0.10      0.38      0.16        98\n",
      "          66       0.00      1.00      0.01        43\n",
      "          67       0.00      0.97      0.01        38\n",
      "          68       0.46      0.77      0.58      2323\n",
      "          69       0.17      0.20      0.18       287\n",
      "          70       0.16      0.12      0.14        41\n",
      "          71       0.67      0.04      0.08        89\n",
      "          72       0.04      0.83      0.07       390\n",
      "          73       0.01      1.00      0.01        75\n",
      "          74       0.00      1.00      0.01        35\n",
      "          75       0.02      0.99      0.03       204\n",
      "          76       0.02      0.37      0.04        75\n",
      "          77       0.38      0.63      0.47       130\n",
      "          78       0.17      0.71      0.28        49\n",
      "          79       0.04      0.14      0.06        56\n",
      "          80       0.09      0.02      0.03       146\n",
      "          81       0.03      0.99      0.06       313\n",
      "          82       0.01      0.98      0.02       123\n",
      "          83       0.01      1.00      0.01        83\n",
      "          84       0.01      1.00      0.01        69\n",
      "          85       0.00      1.00      0.01        52\n",
      "          86       0.05      0.99      0.09       477\n",
      "          87       0.28      0.85      0.42        82\n",
      "          88       0.01      0.99      0.02        88\n",
      "          89       0.02      0.78      0.04        92\n",
      "          90       0.01      0.50      0.01        46\n",
      "          91       0.02      0.86      0.03        66\n",
      "          92       0.21      0.66      0.32        79\n",
      "          93       0.02      1.00      0.03       217\n",
      "          94       0.02      0.67      0.04        95\n",
      "          95       0.00      0.98      0.01        41\n",
      "          96       0.15      1.00      0.26      1865\n",
      "          97       0.06      0.74      0.10       255\n",
      "          98       0.01      0.81      0.01        83\n",
      "          99       0.14      0.24      0.18       187\n",
      "         100       0.45      0.30      0.36       498\n",
      "         101       0.52      0.57      0.54       109\n",
      "         102       0.30      0.46      0.36        76\n",
      "         103       0.28      1.00      0.44      3504\n",
      "         104       0.01      0.91      0.03        55\n",
      "         105       0.03      0.84      0.06       118\n",
      "         106       0.02      0.66      0.04        35\n",
      "         107       0.02      1.00      0.04       239\n",
      "         108       0.05      0.44      0.08       108\n",
      "         109       0.01      1.00      0.02       116\n",
      "         110       0.03      0.56      0.06       200\n",
      "         111       0.03      0.53      0.05       167\n",
      "         112       0.00      1.00      0.01        55\n",
      "         113       0.01      0.96      0.01        73\n",
      "         114       0.01      0.97      0.03       136\n",
      "         115       0.00      0.98      0.01        49\n",
      "         116       0.01      0.92      0.02        92\n",
      "         117       0.01      1.00      0.01        82\n",
      "         118       0.00      1.00      0.01        37\n",
      "         119       0.07      1.00      0.13       867\n",
      "         120       0.06      0.21      0.10       100\n",
      "         121       0.01      0.87      0.02       113\n",
      "         122       0.01      0.83      0.01        83\n",
      "         123       0.33      0.04      0.07        51\n",
      "         124       0.01      0.85      0.02       142\n",
      "         125       0.01      0.65      0.02       195\n",
      "         126       0.04      1.00      0.08       514\n",
      "         127       0.16      0.75      0.26        56\n",
      "         128       0.33      0.01      0.02       236\n",
      "         129       0.33      0.02      0.03       171\n",
      "         130       0.00      1.00      0.01        58\n",
      "         131       0.01      1.00      0.02       123\n",
      "         132       0.38      0.54      0.45        57\n",
      "         133       0.00      1.00      0.01        43\n",
      "         134       0.01      0.86      0.03        57\n",
      "         135       0.02      0.78      0.04       247\n",
      "         136       0.01      0.68      0.02        41\n",
      "         137       0.01      0.86      0.02        44\n",
      "         138       0.02      0.83      0.03        69\n",
      "         139       0.00      1.00      0.00        30\n",
      "         140       0.01      0.97      0.01        70\n",
      "         141       0.00      0.98      0.01        49\n",
      "         142       0.00      1.00      0.01        52\n",
      "         143       0.00      1.00      0.01        47\n",
      "         144       0.21      0.41      0.27       244\n",
      "         145       0.10      0.96      0.18      1137\n",
      "         146       0.00      1.00      0.01        56\n",
      "         147       0.01      1.00      0.02       106\n",
      "         148       0.02      0.70      0.03        80\n",
      "         149       0.06      0.81      0.11       782\n",
      "         150       0.67      0.15      0.24        40\n",
      "         151       0.10      0.32      0.16        60\n",
      "         152       0.05      0.28      0.08        57\n",
      "         153       0.00      1.00      0.01        42\n",
      "         154       0.01      0.65      0.02        88\n",
      "         155       0.02      1.00      0.04       265\n",
      "         156       0.06      0.97      0.11       624\n",
      "         157       0.02      0.54      0.04       137\n",
      "         158       0.18      1.00      0.31      2304\n",
      "         159       0.05      1.00      0.10       680\n",
      "         160       0.01      1.00      0.01        71\n",
      "         161       0.19      0.97      0.32      1980\n",
      "         162       0.08      0.68      0.14      1065\n",
      "         163       0.00      0.48      0.01        56\n",
      "         164       0.03      1.00      0.06       374\n",
      "         165       0.01      1.00      0.01        55\n",
      "         166       0.01      1.00      0.02       108\n",
      "         167       0.10      0.39      0.16        84\n",
      "         168       0.02      0.99      0.03       160\n",
      "         169       0.19      1.00      0.31      2335\n",
      "         170       0.03      1.00      0.05       337\n",
      "         171       0.74      0.54      0.63       113\n",
      "         172       0.45      0.51      0.48        72\n",
      "         173       0.34      0.64      0.44        44\n",
      "         174       0.01      0.61      0.02        62\n",
      "         175       0.00      1.00      0.01        58\n",
      "         176       0.01      1.00      0.01        65\n",
      "         177       0.08      0.05      0.06        43\n",
      "         178       0.00      0.66      0.01        56\n",
      "         179       0.01      0.99      0.02       109\n",
      "         180       0.10      0.42      0.16        57\n",
      "         181       0.04      0.24      0.07        34\n",
      "         182       0.01      0.99      0.02       103\n",
      "         183       0.02      1.00      0.05       298\n",
      "         184       0.02      0.70      0.03        77\n",
      "         185       0.05      0.78      0.10       246\n",
      "         186       0.01      0.69      0.03        39\n",
      "         187       0.01      0.99      0.03       149\n",
      "         188       0.00      1.00      0.01        42\n",
      "         189       0.01      0.61      0.02        59\n",
      "         190       0.06      0.40      0.10        47\n",
      "         191       0.07      1.00      0.14       926\n",
      "         192       0.10      0.05      0.07       413\n",
      "         193       0.00      0.00      0.00       200\n",
      "         194       0.03      0.24      0.05        37\n",
      "         195       0.04      0.33      0.07        36\n",
      "         196       0.68      1.00      0.81      8546\n",
      "         197       0.77      0.88      0.82      7822\n",
      "         198       0.22      0.90      0.36      2186\n",
      "         199       0.76      0.95      0.84      8183\n",
      "         200       0.03      0.68      0.05       356\n",
      "         201       0.68      0.95      0.79      7394\n",
      "         202       0.21      0.97      0.34      2182\n",
      "         203       0.24      0.91      0.38      2304\n",
      "         204       0.01      1.00      0.01        92\n",
      "         205       0.01      0.92      0.02       113\n",
      "         206       0.16      0.13      0.14        39\n",
      "         207       0.45      0.51      0.48        72\n",
      "         208       0.74      0.54      0.62       114\n",
      "         209       0.00      1.00      0.01        58\n",
      "         210       0.02      1.00      0.03       218\n",
      "         211       0.00      1.00      0.01        61\n",
      "         212       0.00      0.00      0.00        37\n",
      "         213       0.01      1.00      0.03       184\n",
      "         214       0.02      0.79      0.03        66\n",
      "         215       0.01      1.00      0.03       172\n",
      "         216       0.01      1.00      0.01        77\n",
      "         217       0.37      0.27      0.31       450\n",
      "         218       0.09      0.45      0.16        69\n",
      "         219       0.23      0.03      0.06        93\n",
      "         220       0.01      1.00      0.03       166\n",
      "         221       0.47      0.08      0.13        89\n",
      "         222       0.00      1.00      0.01        45\n",
      "         223       0.00      1.00      0.01        55\n",
      "         224       0.02      0.02      0.02        49\n",
      "         225       0.01      1.00      0.02       146\n",
      "         226       0.01      1.00      0.01        94\n",
      "         227       0.00      0.66      0.01        56\n",
      "         228       0.01      1.00      0.02       130\n",
      "         229       0.13      0.50      0.21       131\n",
      "         230       0.04      0.30      0.08        70\n",
      "         231       0.04      0.30      0.08        70\n",
      "         232       0.03      0.69      0.05       356\n",
      "         233       0.22      0.96      0.35      2304\n",
      "         234       0.03      0.72      0.05       326\n",
      "         235       0.12      0.13      0.13        30\n",
      "         236       0.23      0.19      0.21       389\n",
      "         237       0.01      0.87      0.01        82\n",
      "         238       0.01      1.00      0.01        65\n",
      "         239       0.00      1.00      0.01        40\n",
      "         240       0.27      0.21      0.24        43\n",
      "         241       0.00      1.00      0.01        41\n",
      "         242       0.23      1.00      0.37      2881\n",
      "         243       1.00      0.01      0.03        67\n",
      "         244       0.01      1.00      0.01        67\n",
      "         245       0.31      0.37      0.34       155\n",
      "         246       0.03      0.90      0.06       112\n",
      "         247       0.33      0.02      0.03       171\n",
      "         248       0.06      0.81      0.12       784\n",
      "         249       0.06      0.28      0.10        40\n",
      "         250       0.04      0.14      0.07        56\n",
      "         251       0.01      1.00      0.02       157\n",
      "         252       0.01      0.41      0.01        61\n",
      "         253       0.12      0.60      0.20       652\n",
      "         254       0.09      0.78      0.16       387\n",
      "         255       0.01      1.00      0.02       149\n",
      "         256       0.01      0.94      0.03       139\n",
      "         257       0.02      1.00      0.03       198\n",
      "         258       0.01      1.00      0.03       175\n",
      "         259       0.04      1.00      0.07       457\n",
      "         260       0.02      1.00      0.03       192\n",
      "         261       0.01      1.00      0.03       160\n",
      "         262       0.01      1.00      0.01        72\n",
      "         263       0.00      1.00      0.01        61\n",
      "         264       0.01      1.00      0.01        64\n",
      "         265       0.02      0.93      0.04       242\n",
      "         266       0.01      0.88      0.02       131\n",
      "         267       0.02      0.79      0.03        66\n",
      "         268       0.01      0.03      0.01        74\n",
      "         269       0.00      1.00      0.01        48\n",
      "         270       0.15      0.39      0.22       126\n",
      "         271       0.10      0.39      0.16        87\n",
      "         272       0.03      1.00      0.07       432\n",
      "         273       0.57      0.21      0.31       271\n",
      "         274       0.02      0.73      0.04       286\n",
      "         275       0.57      0.22      0.31       269\n",
      "         276       0.14      0.35      0.20       150\n",
      "         277       0.02      0.99      0.04       210\n",
      "         278       0.01      0.78      0.02       103\n",
      "         279       0.00      0.98      0.01        50\n",
      "         280       0.99      1.00      1.00     12439\n",
      "         281       0.62      0.14      0.23       912\n",
      "         282       0.00      1.00      0.01        44\n",
      "         283       0.04      1.00      0.08       523\n",
      "         284       0.00      1.00      0.01        52\n",
      "         285       0.03      1.00      0.06       382\n",
      "         286       0.01      1.00      0.02       111\n",
      "         287       0.00      1.00      0.01        57\n",
      "         288       0.06      1.00      0.12       805\n",
      "         289       0.01      1.00      0.02       145\n",
      "         290       0.14      0.19      0.16        48\n",
      "         291       0.17      0.19      0.18        57\n",
      "         292       0.03      0.71      0.05       343\n",
      "         293       0.01      1.00      0.01        74\n",
      "         294       0.01      1.00      0.01        84\n",
      "         295       0.00      1.00      0.01        56\n",
      "         296       0.01      1.00      0.02        99\n",
      "         297       0.03      1.00      0.05       339\n",
      "         298       0.01      1.00      0.02       152\n",
      "         299       0.03      1.00      0.06       384\n",
      "\n",
      "   micro avg       0.06      0.91      0.12    157757\n",
      "   macro avg       0.11      0.74      0.12    157757\n",
      "weighted avg       0.47      0.91      0.53    157757\n",
      " samples avg       0.06      0.93      0.12    157757\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert probabilities to binary predictions\n",
    "new_y_pred_binary = (new_y_pred > 0.5).astype(int)\n",
    "print(classification_report(y_test, new_y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 873us/step\n"
     ]
    }
   ],
   "source": [
    "### Prediction using sample test\n",
    "y_pred_gt = model.predict(X_test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = generate_submission_df(y_pred_gt, test_ids, pred_columns)\n",
    "submission_df.to_csv('./dataset/prediction/sample_prediction_cc.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_pred_gt = post_processing(y_pred_gt, pred_columns, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = generate_submission_df(new_y_pred_gt, test_ids, pred_columns)\n",
    "submission_df.to_csv('./dataset/prediction/sample_prediction_cc_propagate.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Dataset - Molecular Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "selected_ids = create_training_ids('./dataset/test/sampled_test.txt', './dataset/train/train_ids.txt', 1.0)\n",
    "df_train_set = filter_train_data(df_train_set_all, selected_ids, 'molecular_function')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "test_ids = sample_protein_ids('./dataset/test/sampled_test.txt', 1.0)\n",
    "X_test_gt = build_test_data(p_embeddings_data, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|█████████████████████████████████| 53/53 [00:18<00:00,  2.92it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_ID</th>\n",
       "      <th>GO:0016830</th>\n",
       "      <th>GO:0016829</th>\n",
       "      <th>GO:0016833</th>\n",
       "      <th>GO:0003824</th>\n",
       "      <th>GO:0003674</th>\n",
       "      <th>GO:0005488</th>\n",
       "      <th>GO:0005515</th>\n",
       "      <th>GO:0003676</th>\n",
       "      <th>GO:0003690</th>\n",
       "      <th>...</th>\n",
       "      <th>GO:0001091</th>\n",
       "      <th>GO:0042287</th>\n",
       "      <th>GO:0050897</th>\n",
       "      <th>GO:0015923</th>\n",
       "      <th>GO:0016251</th>\n",
       "      <th>GO:0004559</th>\n",
       "      <th>GO:0030515</th>\n",
       "      <th>GO:0016863</th>\n",
       "      <th>GO:0005337</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O81027</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0491, 0.0389, -0.0178, 0.02779, -0.00568, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q8IXT2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.02515, -0.01331, 0.00575, 0.004353, -0.069...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q9WUC4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.06134, -0.00452, 0.01472, 0.001324, 0.03162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q6P6T4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.02074, 0.09515, 0.0519, 0.00766, -0.02692, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P04014</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.01222, -0.0453, 0.0269, -0.00953, -0.01057,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 841 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protein_ID  GO:0016830  GO:0016829  GO:0016833  GO:0003824  GO:0003674  \\\n",
       "0     O81027           1           1           1           1           1   \n",
       "1     Q8IXT2           0           0           0           0           1   \n",
       "2     Q9WUC4           0           0           0           0           1   \n",
       "3     Q6P6T4           0           0           0           0           1   \n",
       "4     P04014           0           0           0           1           1   \n",
       "\n",
       "   GO:0005488  GO:0005515  GO:0003676  GO:0003690  ...  GO:0001091  \\\n",
       "0           1           1           0           0  ...           0   \n",
       "1           1           0           1           1  ...           0   \n",
       "2           1           1           0           0  ...           0   \n",
       "3           1           1           0           0  ...           0   \n",
       "4           1           1           1           0  ...           0   \n",
       "\n",
       "   GO:0042287  GO:0050897  GO:0015923  GO:0016251  GO:0004559  GO:0030515  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   GO:0016863  GO:0005337                                          embedding  \n",
       "0           0           0  [0.0491, 0.0389, -0.0178, 0.02779, -0.00568, 0...  \n",
       "1           0           0  [-0.02515, -0.01331, 0.00575, 0.004353, -0.069...  \n",
       "2           0           0  [0.06134, -0.00452, 0.01472, 0.001324, 0.03162...  \n",
       "3           0           0  [0.02074, 0.09515, 0.0519, 0.00766, -0.02692, ...  \n",
       "4           0           0  [0.01222, -0.0453, 0.0269, -0.00953, -0.01057,...  \n",
       "\n",
       "[5 rows x 841 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded = encode_go_terms_sparse(df_train_set)\n",
    "df_encoded = get_embeddings(df_encoded, p_embeddings_data)\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top N labels, for molecular function we pick top 450\n",
    "freq_df = pd.read_csv('./dataset/train/molecular_function_freq.csv')[:450]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_columns = df_encoded.iloc[:, 3:-1]\n",
    "pred_columns = get_top_freq(y_columns.columns.tolist(), set(freq_df['id']))\n",
    "y_columns = y_columns[pred_columns]\n",
    "y = create_y(y_columns)\n",
    "X = create_X(df_encoded,'embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0686 - f1_score: 0.4394\n",
      "Epoch 2/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0445 - f1_score: 0.5558\n",
      "Epoch 3/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0407 - f1_score: 0.5962\n",
      "Epoch 4/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0384 - f1_score: 0.6216\n",
      "Epoch 5/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0368 - f1_score: 0.6404\n",
      "Epoch 6/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0355 - f1_score: 0.6539\n",
      "Epoch 7/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0345 - f1_score: 0.6640\n",
      "Epoch 8/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0337 - f1_score: 0.6729\n",
      "Epoch 9/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0330 - f1_score: 0.6792\n",
      "Epoch 10/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0323 - f1_score: 0.6865\n",
      "Epoch 11/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0317 - f1_score: 0.6912\n",
      "Epoch 12/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0312 - f1_score: 0.6975\n",
      "Epoch 13/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0307 - f1_score: 0.7011\n",
      "Epoch 14/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0303 - f1_score: 0.7060\n",
      "Epoch 15/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0298 - f1_score: 0.7095\n",
      "Epoch 16/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0295 - f1_score: 0.7140\n",
      "Epoch 17/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0291 - f1_score: 0.7175\n",
      "Epoch 18/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0288 - f1_score: 0.7210\n",
      "Epoch 19/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0284 - f1_score: 0.7240\n",
      "Epoch 20/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0281 - f1_score: 0.7274\n",
      "Epoch 21/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0279 - f1_score: 0.7299\n",
      "Epoch 22/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0276 - f1_score: 0.7329\n",
      "Epoch 23/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0273 - f1_score: 0.7355\n",
      "Epoch 24/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0270 - f1_score: 0.7385\n",
      "Epoch 25/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0268 - f1_score: 0.7406\n",
      "Epoch 26/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0266 - f1_score: 0.7431\n",
      "Epoch 27/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0263 - f1_score: 0.7447\n",
      "Epoch 28/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0261 - f1_score: 0.7466\n",
      "Epoch 29/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0259 - f1_score: 0.7481\n",
      "Epoch 30/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0257 - f1_score: 0.7505\n",
      "Epoch 31/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0255 - f1_score: 0.7523\n",
      "Epoch 32/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0254 - f1_score: 0.7535\n",
      "Epoch 33/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0251 - f1_score: 0.7561\n",
      "Epoch 34/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0250 - f1_score: 0.7577\n",
      "Epoch 35/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0248 - f1_score: 0.7590\n",
      "Epoch 36/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0247 - f1_score: 0.7599\n",
      "Epoch 37/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0245 - f1_score: 0.7622\n",
      "Epoch 38/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0243 - f1_score: 0.7639\n",
      "Epoch 39/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0242 - f1_score: 0.7650\n",
      "Epoch 40/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0241 - f1_score: 0.7669\n",
      "Epoch 41/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0239 - f1_score: 0.7681\n",
      "Epoch 42/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0238 - f1_score: 0.7692\n",
      "Epoch 43/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0237 - f1_score: 0.7705\n",
      "Epoch 44/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0235 - f1_score: 0.7717\n",
      "Epoch 45/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0234 - f1_score: 0.7729\n",
      "Epoch 46/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0233 - f1_score: 0.7739\n",
      "Epoch 47/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0231 - f1_score: 0.7756\n",
      "Epoch 48/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0230 - f1_score: 0.7767\n",
      "Epoch 49/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0229 - f1_score: 0.7776\n",
      "Epoch 50/50\n",
      "1453/1453 [==============================] - 2s 1ms/step - loss: 0.0228 - f1_score: 0.7783\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "model = train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257/257 [==============================] - 0s 520us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post Processing - Molecular Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_pred = post_processing(y_pred, pred_columns, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation - Molecular Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      3627\n",
      "           1       1.00      1.00      1.00      8205\n",
      "           2       0.84      0.87      0.85      5453\n",
      "           3       0.75      0.75      0.75      4182\n",
      "           4       0.76      0.76      0.76      1431\n",
      "           5       0.61      0.61      0.61       488\n",
      "           6       0.72      0.71      0.72       606\n",
      "           7       0.72      0.65      0.68      1795\n",
      "           8       0.60      0.61      0.61       446\n",
      "           9       0.79      0.70      0.74       845\n",
      "          10       0.35      0.09      0.15       579\n",
      "          11       0.00      0.00      0.00        25\n",
      "          12       0.74      0.45      0.56       414\n",
      "          13       0.71      0.63      0.67       139\n",
      "          14       0.73      0.59      0.65        51\n",
      "          15       0.79      0.45      0.58        33\n",
      "          16       0.59      0.59      0.59        49\n",
      "          17       0.73      0.73      0.73       324\n",
      "          18       0.64      0.46      0.53       253\n",
      "          19       0.00      0.00      0.00       198\n",
      "          20       0.53      0.51      0.52       380\n",
      "          21       0.53      0.52      0.53       377\n",
      "          22       0.56      0.62      0.59       471\n",
      "          23       0.40      0.11      0.18        89\n",
      "          24       0.56      0.66      0.60       347\n",
      "          25       0.55      0.14      0.22        88\n",
      "          26       0.60      0.16      0.25        77\n",
      "          27       0.63      0.56      0.59       293\n",
      "          28       0.74      0.65      0.69       614\n",
      "          29       1.00      0.87      0.93        31\n",
      "          30       0.81      0.67      0.73       143\n",
      "          31       0.64      0.57      0.61       206\n",
      "          32       1.00      0.87      0.93        31\n",
      "          33       0.75      0.63      0.69        68\n",
      "          34       0.66      0.35      0.46       291\n",
      "          35       0.55      0.57      0.56       389\n",
      "          36       0.60      0.55      0.57       589\n",
      "          37       0.61      0.35      0.44       149\n",
      "          38       0.82      0.77      0.79      1004\n",
      "          39       0.81      0.59      0.68        49\n",
      "          40       0.83      0.74      0.78        98\n",
      "          41       0.88      0.56      0.68        27\n",
      "          42       0.87      0.83      0.85       123\n",
      "          43       0.86      0.82      0.84      1379\n",
      "          44       0.86      0.75      0.80       143\n",
      "          45       0.88      0.52      0.65        27\n",
      "          46       0.83      0.77      0.80        44\n",
      "          47       0.33      0.29      0.31       143\n",
      "          48       0.34      0.29      0.31       167\n",
      "          49       0.24      0.16      0.19       119\n",
      "          50       0.50      0.47      0.48       208\n",
      "          51       0.43      0.18      0.25        56\n",
      "          52       0.75      0.68      0.71        75\n",
      "          53       0.61      0.65      0.63        43\n",
      "          54       0.71      0.54      0.61       139\n",
      "          55       0.89      0.83      0.86       254\n",
      "          56       0.79      0.76      0.77      1182\n",
      "          57       0.70      0.26      0.38        27\n",
      "          58       0.46      0.19      0.27       782\n",
      "          59       0.51      0.20      0.29       426\n",
      "          60       0.52      0.21      0.30       390\n",
      "          61       0.51      0.06      0.10       834\n",
      "          62       0.62      0.13      0.22        60\n",
      "          63       0.38      0.16      0.23       310\n",
      "          64       0.89      0.80      0.84       598\n",
      "          65       0.90      0.84      0.87       467\n",
      "          66       0.85      0.82      0.84       410\n",
      "          67       0.78      0.89      0.83        36\n",
      "          68       0.35      0.08      0.13       112\n",
      "          69       0.43      0.07      0.12       134\n",
      "          70       0.45      0.15      0.22       199\n",
      "          71       0.38      0.06      0.10       103\n",
      "          72       0.47      0.11      0.17       150\n",
      "          73       0.76      0.59      0.66        92\n",
      "          74       0.48      0.07      0.12       139\n",
      "          75       0.59      0.13      0.21       233\n",
      "          76       0.20      0.03      0.06        62\n",
      "          77       0.11      0.02      0.03        54\n",
      "          78       0.91      0.58      0.71        72\n",
      "          79       0.92      0.62      0.74        39\n",
      "          80       0.84      0.70      0.76       140\n",
      "          81       0.84      0.69      0.76       299\n",
      "          82       0.88      0.79      0.83       613\n",
      "          83       0.94      0.69      0.79        42\n",
      "          84       0.94      0.63      0.76        52\n",
      "          85       0.40      0.21      0.28       335\n",
      "          86       0.41      0.20      0.27       295\n",
      "          87       0.44      0.10      0.16        40\n",
      "          88       0.41      0.20      0.27       295\n",
      "          89       0.42      0.16      0.23       446\n",
      "          90       0.41      0.15      0.22       420\n",
      "          91       0.89      0.85      0.87       319\n",
      "          92       0.80      0.86      0.83        14\n",
      "          93       0.84      0.63      0.72        57\n",
      "          94       0.56      0.18      0.27       124\n",
      "          95       0.89      0.80      0.84       162\n",
      "          96       0.88      0.79      0.83       216\n",
      "          97       0.79      0.74      0.76       466\n",
      "          98       0.43      0.18      0.26       217\n",
      "          99       0.00      0.00      0.00        45\n",
      "         100       0.00      0.00      0.00        20\n",
      "         101       0.00      0.00      0.00        27\n",
      "         102       0.54      0.06      0.11       507\n",
      "         103       0.43      0.09      0.15       169\n",
      "         104       0.76      0.63      0.69       108\n",
      "         105       0.49      0.35      0.41       182\n",
      "         106       0.50      0.35      0.41       182\n",
      "         107       0.50      0.36      0.42       181\n",
      "         108       0.81      0.71      0.76       104\n",
      "         109       0.86      0.65      0.74       118\n",
      "         110       0.82      0.85      0.83        62\n",
      "         111       0.53      0.72      0.61        25\n",
      "         112       0.76      0.79      0.77       280\n",
      "         113       0.87      0.91      0.89       609\n",
      "         114       0.82      0.81      0.82       209\n",
      "         115       0.82      0.80      0.81       209\n",
      "         116       0.86      0.90      0.88       651\n",
      "         117       0.80      0.71      0.75       347\n",
      "         118       0.84      0.81      0.83       151\n",
      "         119       0.85      0.86      0.85       130\n",
      "         120       0.56      0.70      0.62        27\n",
      "         121       0.80      0.52      0.63       122\n",
      "         122       0.69      0.58      0.63        69\n",
      "         123       0.97      0.78      0.86        41\n",
      "         124       0.89      0.71      0.79        34\n",
      "         125       0.53      0.10      0.17        88\n",
      "         126       0.43      0.01      0.02       262\n",
      "         127       0.67      0.02      0.04       323\n",
      "         128       0.88      0.62      0.73        37\n",
      "         129       0.78      0.25      0.38        28\n",
      "         130       0.91      0.53      0.67        19\n",
      "         131       0.92      0.89      0.90       209\n",
      "         132       0.76      0.62      0.68        21\n",
      "         133       0.86      0.56      0.68        34\n",
      "         134       0.82      0.38      0.51        24\n",
      "         135       0.59      0.30      0.40        33\n",
      "         136       0.15      0.12      0.13        17\n",
      "         137       0.59      0.30      0.40        33\n",
      "         138       0.63      0.54      0.58       136\n",
      "         139       0.75      0.58      0.65        52\n",
      "         140       0.81      0.54      0.65        46\n",
      "         141       0.88      0.53      0.66        68\n",
      "         142       0.68      0.68      0.68        25\n",
      "         143       0.85      0.88      0.86       162\n",
      "         144       0.69      0.35      0.46        26\n",
      "         145       0.70      0.49      0.58       135\n",
      "         146       0.65      0.45      0.53        38\n",
      "         147       0.70      0.48      0.57       126\n",
      "         148       0.70      0.51      0.59       122\n",
      "         149       0.83      0.11      0.19        47\n",
      "         150       0.38      0.04      0.07        83\n",
      "         151       0.85      0.75      0.80        92\n",
      "         152       0.88      0.73      0.80       126\n",
      "         153       0.76      0.45      0.57        29\n",
      "         154       0.29      0.11      0.16        97\n",
      "         155       0.82      0.70      0.76       349\n",
      "         156       0.83      0.81      0.82       117\n",
      "         157       0.82      0.70      0.76       346\n",
      "         158       0.78      0.70      0.74       257\n",
      "         159       0.00      0.00      0.00        37\n",
      "         160       0.74      0.36      0.49        47\n",
      "         161       0.33      0.04      0.07        26\n",
      "         162       0.53      0.26      0.35        31\n",
      "         163       0.67      0.88      0.76        16\n",
      "         164       0.79      0.46      0.58        41\n",
      "         165       0.79      0.81      0.80        27\n",
      "         166       0.76      0.66      0.70        38\n",
      "         167       0.83      0.79      0.81        24\n",
      "         168       0.74      0.78      0.76        41\n",
      "         169       0.69      0.88      0.77        99\n",
      "         170       0.74      0.84      0.79        31\n",
      "         171       0.62      0.51      0.56        45\n",
      "         172       0.62      0.53      0.57        75\n",
      "         173       0.72      0.62      0.67       130\n",
      "         174       0.73      0.56      0.63        77\n",
      "         175       0.81      0.75      0.78        67\n",
      "         176       0.86      0.83      0.84        23\n",
      "         177       0.96      0.76      0.85        34\n",
      "         178       0.85      0.68      0.76        66\n",
      "         179       0.78      0.54      0.64        90\n",
      "         180       0.64      0.54      0.58        26\n",
      "         181       0.63      0.41      0.50        64\n",
      "         182       0.90      0.72      0.80        25\n",
      "         183       0.73      0.75      0.74        72\n",
      "         184       0.94      0.71      0.81        41\n",
      "         185       0.83      0.79      0.81        19\n",
      "         186       0.69      0.70      0.69        47\n",
      "         187       0.74      0.76      0.75        70\n",
      "         188       0.82      0.84      0.83        38\n",
      "         189       0.77      0.78      0.77       122\n",
      "         190       0.86      0.66      0.75        29\n",
      "         191       0.82      0.71      0.76       306\n",
      "         192       0.87      0.69      0.77        29\n",
      "         193       0.82      0.82      0.82       175\n",
      "         194       0.71      0.85      0.77       116\n",
      "         195       0.83      0.74      0.78       365\n",
      "         196       0.83      0.83      0.83        18\n",
      "         197       0.85      0.52      0.65        44\n",
      "         198       0.00      0.00      0.00        16\n",
      "         199       1.00      0.01      0.03        72\n",
      "         200       0.85      0.44      0.58        25\n",
      "         201       0.80      0.31      0.44        52\n",
      "         202       0.55      0.36      0.43        59\n",
      "         203       0.82      0.62      0.71       144\n",
      "         204       0.83      0.71      0.77       136\n",
      "         205       0.56      0.32      0.40        63\n",
      "         206       0.81      0.75      0.78       122\n",
      "         207       0.36      0.11      0.16        38\n",
      "         208       0.73      0.85      0.79        55\n",
      "         209       0.70      0.47      0.56       117\n",
      "         210       0.60      0.43      0.50        14\n",
      "         211       0.72      0.68      0.70       129\n",
      "         212       0.88      0.68      0.76        31\n",
      "         213       0.80      0.61      0.69        33\n",
      "         214       0.78      0.52      0.62       201\n",
      "         215       0.75      0.44      0.55        41\n",
      "         216       0.81      0.58      0.67       118\n",
      "         217       0.81      0.49      0.61        77\n",
      "         218       0.88      0.70      0.78        40\n",
      "         219       0.80      0.69      0.74       282\n",
      "         220       0.82      0.49      0.62        65\n",
      "         221       0.84      0.70      0.76       211\n",
      "         222       0.91      0.50      0.65        40\n",
      "         223       0.75      0.72      0.74        29\n",
      "         224       0.82      0.49      0.62        65\n",
      "         225       0.75      0.50      0.60       141\n",
      "         226       0.78      0.72      0.75        29\n",
      "         227       0.52      0.27      0.36        51\n",
      "         228       0.62      0.35      0.44       113\n",
      "         229       0.67      0.29      0.41       276\n",
      "         230       0.73      0.80      0.76        54\n",
      "         231       0.77      0.82      0.79        33\n",
      "         232       0.64      0.50      0.56       133\n",
      "         233       0.78      0.79      0.79        63\n",
      "         234       0.68      0.73      0.70        59\n",
      "         235       0.70      0.43      0.53       169\n",
      "         236       0.88      0.45      0.60        31\n",
      "         237       0.91      0.65      0.75        31\n",
      "         238       0.81      0.63      0.71       204\n",
      "         239       0.39      0.25      0.31       147\n",
      "         240       0.44      0.35      0.39        68\n",
      "         241       0.69      0.69      0.69        26\n",
      "         242       0.78      0.74      0.76        43\n",
      "         243       0.66      0.78      0.71        49\n",
      "         244       0.69      0.76      0.72        49\n",
      "         245       0.82      0.65      0.72        62\n",
      "         246       0.75      0.75      0.75        40\n",
      "         247       0.41      0.28      0.33        25\n",
      "         248       0.50      0.05      0.10        73\n",
      "         249       0.35      0.06      0.11        97\n",
      "         250       1.00      0.03      0.05        39\n",
      "         251       0.64      0.17      0.27        94\n",
      "         252       0.62      0.23      0.34        69\n",
      "         253       0.00      0.00      0.00        31\n",
      "         254       0.75      0.75      0.75        55\n",
      "         255       0.74      0.66      0.69        90\n",
      "         256       0.61      0.59      0.60        37\n",
      "         257       0.80      0.52      0.63        23\n",
      "         258       0.73      0.62      0.67        88\n",
      "         259       0.67      0.44      0.53        41\n",
      "         260       0.57      0.11      0.19        35\n",
      "         261       0.93      0.68      0.78        37\n",
      "         262       0.92      0.56      0.69        59\n",
      "         263       0.89      0.55      0.68        56\n",
      "         264       0.91      0.62      0.74        66\n",
      "         265       1.00      0.04      0.08        25\n",
      "         266       0.45      0.29      0.35        35\n",
      "         267       0.91      0.53      0.67        19\n",
      "         268       0.73      0.55      0.63        58\n",
      "         269       0.71      0.55      0.62        77\n",
      "         270       0.58      0.35      0.44        40\n",
      "         271       0.58      0.19      0.28        81\n",
      "         272       0.40      0.13      0.20        30\n",
      "         273       0.31      0.38      0.34        13\n",
      "         274       0.61      0.76      0.68        62\n",
      "         275       0.79      0.78      0.78       136\n",
      "         276       0.78      0.78      0.78       136\n",
      "         277       0.67      0.58      0.62        79\n",
      "         278       0.62      0.57      0.59        56\n",
      "         279       0.41      0.18      0.25       177\n",
      "         280       0.40      0.08      0.13        26\n",
      "         281       0.41      0.23      0.29       240\n",
      "         282       0.32      0.21      0.26        42\n",
      "         283       0.25      0.13      0.17        38\n",
      "         284       0.77      0.40      0.53        42\n",
      "         285       0.57      0.17      0.26        48\n",
      "         286       0.90      0.77      0.83        35\n",
      "         287       1.00      0.95      0.98        22\n",
      "         288       1.00      0.03      0.05        40\n",
      "         289       0.69      0.31      0.42        36\n",
      "         290       0.73      0.39      0.51        49\n",
      "         291       0.63      0.32      0.43        37\n",
      "         292       0.79      0.71      0.75        76\n",
      "         293       0.82      0.58      0.68        24\n",
      "         294       0.88      0.79      0.84        29\n",
      "         295       0.92      0.79      0.85        29\n",
      "         296       0.80      0.30      0.44        66\n",
      "         297       0.53      0.08      0.14        97\n",
      "         298       0.54      0.20      0.29        35\n",
      "         299       0.92      0.39      0.55        31\n",
      "         300       0.63      0.55      0.59        22\n",
      "         301       0.88      0.56      0.68        27\n",
      "         302       0.62      0.62      0.62        34\n",
      "         303       0.58      0.73      0.64        26\n",
      "         304       0.77      0.50      0.61        20\n",
      "         305       1.00      0.83      0.91        24\n",
      "         306       0.81      0.74      0.77        65\n",
      "         307       0.80      0.73      0.76        48\n",
      "         308       0.73      0.76      0.75        29\n",
      "         309       0.71      0.71      0.71        35\n",
      "         310       0.75      0.68      0.72        57\n",
      "         311       0.39      0.20      0.27        69\n",
      "         312       0.38      0.22      0.28       197\n",
      "         313       0.40      0.23      0.29       212\n",
      "         314       0.41      0.20      0.27        69\n",
      "         315       0.30      0.09      0.14        64\n",
      "         316       0.29      0.09      0.14        67\n",
      "         317       0.00      0.00      0.00        18\n",
      "         318       0.36      0.18      0.24       108\n",
      "         319       0.41      0.19      0.26       133\n",
      "         320       0.38      0.21      0.27       155\n",
      "         321       0.54      0.30      0.39        23\n",
      "         322       0.58      0.41      0.48        17\n",
      "         323       0.00      0.00      0.00        23\n",
      "         324       0.72      0.52      0.60        92\n",
      "         325       0.51      0.29      0.37        85\n",
      "         326       0.72      0.47      0.57        59\n",
      "         327       0.53      0.56      0.55        16\n",
      "         328       0.56      0.56      0.56        18\n",
      "         329       0.64      0.27      0.38        52\n",
      "         330       0.41      0.08      0.13       177\n",
      "         331       0.34      0.08      0.13       202\n",
      "         332       0.67      0.55      0.60        22\n",
      "         333       0.44      0.26      0.33        27\n",
      "         334       0.83      0.71      0.77        63\n",
      "         335       0.75      0.45      0.56        20\n",
      "         336       0.83      0.50      0.62        20\n",
      "         337       0.00      0.00      0.00        35\n",
      "         338       0.62      0.22      0.32        23\n",
      "         339       0.00      0.00      0.00        36\n",
      "         340       0.36      0.11      0.17        36\n",
      "         341       0.40      0.03      0.06        63\n",
      "         342       0.00      0.00      0.00        39\n",
      "         343       0.92      0.55      0.69        20\n",
      "         344       0.61      0.54      0.58        35\n",
      "         345       0.92      0.65      0.76        37\n",
      "         346       0.22      0.03      0.06        62\n",
      "         347       0.25      0.04      0.07        52\n",
      "         348       0.56      0.26      0.35        35\n",
      "         349       0.97      0.90      0.93        31\n",
      "         350       0.67      0.07      0.13        28\n",
      "         351       0.33      0.04      0.07        24\n",
      "         352       0.50      0.05      0.08        22\n",
      "         353       0.63      0.73      0.68        30\n",
      "         354       0.81      0.81      0.81        26\n",
      "         355       0.83      0.65      0.73        31\n",
      "         356       0.48      0.20      0.28        65\n",
      "         357       0.46      0.14      0.22        76\n",
      "         358       0.58      0.27      0.37        26\n",
      "         359       0.75      0.46      0.57        46\n",
      "         360       0.52      0.08      0.14       157\n",
      "         361       0.52      0.12      0.19       119\n",
      "         362       1.00      0.67      0.80        21\n",
      "         363       0.86      0.35      0.50        17\n",
      "         364       0.40      0.12      0.19        80\n",
      "         365       0.75      0.05      0.09        63\n",
      "         366       0.75      0.07      0.13        41\n",
      "         367       0.62      0.41      0.49        32\n",
      "         368       0.70      0.66      0.68        29\n",
      "         369       0.00      0.00      0.00        25\n",
      "         370       0.00      0.00      0.00        23\n",
      "         371       0.73      0.53      0.61        36\n",
      "         372       0.60      0.23      0.33        26\n",
      "         373       0.74      0.50      0.60        34\n",
      "         374       0.68      0.40      0.50        48\n",
      "         375       0.42      0.17      0.24        48\n",
      "         376       0.88      0.67      0.76        54\n",
      "         377       0.00      0.00      0.00        29\n",
      "         378       0.75      0.53      0.62        34\n",
      "         379       0.87      0.55      0.67        49\n",
      "         380       0.86      0.41      0.56        29\n",
      "         381       0.78      0.39      0.52        36\n",
      "         382       0.86      0.38      0.52        32\n",
      "         383       0.91      0.77      0.83        26\n",
      "         384       0.76      0.53      0.63        30\n",
      "         385       0.57      0.26      0.36        46\n",
      "         386       0.60      0.29      0.39        42\n",
      "         387       0.86      0.86      0.86        22\n",
      "         388       0.60      0.21      0.31        57\n",
      "         389       0.71      0.33      0.45        15\n",
      "         390       1.00      0.16      0.27        19\n",
      "         391       0.00      0.00      0.00        19\n",
      "         392       0.82      0.85      0.84        33\n",
      "         393       0.62      0.62      0.62        24\n",
      "         394       0.85      0.79      0.81        14\n",
      "         395       0.61      0.58      0.59        19\n",
      "         396       0.83      0.75      0.79        20\n",
      "         397       0.43      0.14      0.21        21\n",
      "         398       0.57      0.11      0.19        35\n",
      "         399       0.33      0.03      0.05        36\n",
      "         400       0.45      0.20      0.28        49\n",
      "         401       0.72      0.65      0.68        20\n",
      "         402       0.67      0.08      0.15        24\n",
      "         403       0.74      0.48      0.58        42\n",
      "         404       0.17      0.06      0.08        18\n",
      "         405       1.00      0.03      0.06        35\n",
      "         406       0.62      0.05      0.09       108\n",
      "         407       0.54      0.54      0.54        13\n",
      "         408       0.62      0.14      0.23        71\n",
      "         409       0.81      0.90      0.85        29\n",
      "         410       0.55      0.17      0.26        36\n",
      "         411       0.25      0.02      0.04        48\n",
      "         412       0.00      0.00      0.00        12\n",
      "         413       0.70      0.61      0.65        23\n",
      "         414       0.78      0.55      0.64        33\n",
      "         415       0.33      0.02      0.04        50\n",
      "         416       0.67      0.06      0.11        33\n",
      "         417       0.50      0.19      0.27        32\n",
      "         418       0.00      0.00      0.00        33\n",
      "         419       0.36      0.21      0.26        24\n",
      "         420       0.80      0.52      0.63        23\n",
      "         421       0.83      0.23      0.36        22\n",
      "         422       0.25      0.07      0.11        14\n",
      "         423       0.75      0.07      0.12        46\n",
      "         424       0.37      0.33      0.35        21\n",
      "         425       0.50      0.40      0.44        20\n",
      "         426       0.62      0.53      0.57        19\n",
      "         427       0.67      0.53      0.59        19\n",
      "         428       0.00      0.00      0.00        27\n",
      "         429       0.64      0.45      0.53        20\n",
      "         430       0.75      0.67      0.71        27\n",
      "         431       0.36      0.13      0.19        31\n",
      "         432       0.50      0.27      0.35        15\n",
      "         433       0.50      0.27      0.35        15\n",
      "         434       0.31      0.19      0.24        21\n",
      "         435       0.50      0.13      0.21        15\n",
      "         436       0.36      0.09      0.14        46\n",
      "         437       0.67      0.56      0.61        32\n",
      "         438       0.57      0.57      0.57        14\n",
      "         439       0.45      0.53      0.49        17\n",
      "         440       0.33      0.03      0.06        29\n",
      "         441       0.50      0.04      0.07        25\n",
      "         442       0.36      0.19      0.25        21\n",
      "         443       0.50      0.29      0.36        14\n",
      "         444       0.00      0.00      0.00        20\n",
      "         445       0.00      0.00      0.00        27\n",
      "         446       0.60      0.12      0.21        24\n",
      "         447       0.00      0.00      0.00        15\n",
      "\n",
      "   micro avg       0.78      0.63      0.69     73636\n",
      "   macro avg       0.64      0.45      0.50     73636\n",
      "weighted avg       0.73      0.63      0.65     73636\n",
      " samples avg       0.81      0.68      0.70     73636\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satria/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Convert probabilities to binary predictions\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 546us/step\n"
     ]
    }
   ],
   "source": [
    "### Prediction using sample test\n",
    "y_pred_gt = model.predict(X_test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = generate_submission_df(y_pred_gt, test_ids, pred_columns)\n",
    "submission_df.to_csv('./dataset/prediction/sample_prediction_mf.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_pred_gt = post_processing(y_pred_gt, pred_columns, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = generate_submission_df(new_y_pred_gt, test_ids, pred_columns)\n",
    "submission_df.to_csv('./dataset/prediction/sample_prediction_mf_propagate.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess - Biological Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "selected_ids = create_training_ids('./dataset/test/sampled_test.txt', './dataset/train/train_ids.txt', 0.6)\n",
    "df_train_set = filter_train_data(df_train_set_all, selected_ids, 'biological_process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "test_ids = sample_protein_ids('./dataset/test/sampled_test.txt', 1.0)\n",
    "X_test_gt = build_test_data(p_embeddings_data, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding: 100%|███████████████████████████████| 157/157 [00:58<00:00,  2.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protein_ID</th>\n",
       "      <th>GO:0090304</th>\n",
       "      <th>GO:0044271</th>\n",
       "      <th>GO:0010467</th>\n",
       "      <th>GO:0034641</th>\n",
       "      <th>GO:0016070</th>\n",
       "      <th>GO:0006366</th>\n",
       "      <th>GO:0044249</th>\n",
       "      <th>GO:0043170</th>\n",
       "      <th>GO:0009058</th>\n",
       "      <th>...</th>\n",
       "      <th>GO:0008360</th>\n",
       "      <th>GO:0030522</th>\n",
       "      <th>GO:1901264</th>\n",
       "      <th>GO:0051983</th>\n",
       "      <th>GO:0042129</th>\n",
       "      <th>GO:0050777</th>\n",
       "      <th>GO:0051445</th>\n",
       "      <th>GO:0071322</th>\n",
       "      <th>GO:2000027</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q04418</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.022, -0.06964, -0.007042, 0.0544, -0.04633...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q7ZT12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.04028, -0.03357, 0.1046, 0.0669, -0.07935, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q6DBW0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.01106, 0.02277, 0.02895, 0.03293, -0.00641,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q9WUC4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.06134, -0.00452, 0.01472, 0.001324, 0.03162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q03370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.014366, -0.0655, 0.0208, 0.0652, 0.0433, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1489 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Protein_ID  GO:0090304  GO:0044271  GO:0010467  GO:0034641  GO:0016070  \\\n",
       "0     Q04418           1           1           1           1           1   \n",
       "1     Q7ZT12           0           0           0           0           0   \n",
       "2     Q6DBW0           0           0           0           0           0   \n",
       "3     Q9WUC4           0           0           0           0           0   \n",
       "4     Q03370           0           0           0           0           0   \n",
       "\n",
       "   GO:0006366  GO:0044249  GO:0043170  GO:0009058  ...  GO:0008360  \\\n",
       "0           1           1           1           1  ...           0   \n",
       "1           0           0           0           0  ...           0   \n",
       "2           0           0           0           0  ...           0   \n",
       "3           0           0           0           0  ...           0   \n",
       "4           0           0           0           0  ...           0   \n",
       "\n",
       "   GO:0030522  GO:1901264  GO:0051983  GO:0042129  GO:0050777  GO:0051445  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   GO:0071322  GO:2000027                                          embedding  \n",
       "0           0           0  [-0.022, -0.06964, -0.007042, 0.0544, -0.04633...  \n",
       "1           0           0  [0.04028, -0.03357, 0.1046, 0.0669, -0.07935, ...  \n",
       "2           0           0  [0.01106, 0.02277, 0.02895, 0.03293, -0.00641,...  \n",
       "3           0           0  [0.06134, -0.00452, 0.01472, 0.001324, 0.03162...  \n",
       "4           0           0  [-0.014366, -0.0655, 0.0208, 0.0652, 0.0433, 0...  \n",
       "\n",
       "[5 rows x 1489 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded = encode_go_terms_sparse(df_train_set)\n",
    "df_encoded = get_embeddings(df_encoded, p_embeddings_data)\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top N labels, for biological process 1100\n",
    "freq_df = pd.read_csv('./dataset/train/biological_process_freq.csv')[:1100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_columns = df_encoded.iloc[:, 3:-1]\n",
    "pred_columns = get_top_freq(y_columns.columns.tolist(), set(freq_df['id']))\n",
    "y_columns = y_columns[pred_columns]\n",
    "y = create_y(y_columns)\n",
    "X = create_X(df_encoded,'embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1304/1304 [==============================] - 3s 2ms/step - loss: 0.1049 - f1_score: 0.1800\n",
      "Epoch 2/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0864 - f1_score: 0.2548\n",
      "Epoch 3/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0836 - f1_score: 0.2760\n",
      "Epoch 4/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0818 - f1_score: 0.2901\n",
      "Epoch 5/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0805 - f1_score: 0.3023\n",
      "Epoch 6/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0794 - f1_score: 0.3121\n",
      "Epoch 7/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0785 - f1_score: 0.3213\n",
      "Epoch 8/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0776 - f1_score: 0.3291\n",
      "Epoch 9/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0768 - f1_score: 0.3370\n",
      "Epoch 10/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0761 - f1_score: 0.3441\n",
      "Epoch 11/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0755 - f1_score: 0.3503\n",
      "Epoch 12/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0749 - f1_score: 0.3564\n",
      "Epoch 13/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0743 - f1_score: 0.3626\n",
      "Epoch 14/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0738 - f1_score: 0.3688\n",
      "Epoch 15/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0732 - f1_score: 0.3740\n",
      "Epoch 16/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0727 - f1_score: 0.3793\n",
      "Epoch 17/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0722 - f1_score: 0.3847\n",
      "Epoch 18/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0717 - f1_score: 0.3900\n",
      "Epoch 19/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0713 - f1_score: 0.3934\n",
      "Epoch 20/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0709 - f1_score: 0.3985\n",
      "Epoch 21/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0704 - f1_score: 0.4035\n",
      "Epoch 22/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0701 - f1_score: 0.4079\n",
      "Epoch 23/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0697 - f1_score: 0.4118\n",
      "Epoch 24/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0693 - f1_score: 0.4163\n",
      "Epoch 25/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0690 - f1_score: 0.4199\n",
      "Epoch 26/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0686 - f1_score: 0.4239\n",
      "Epoch 27/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0683 - f1_score: 0.4272\n",
      "Epoch 28/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0680 - f1_score: 0.4308\n",
      "Epoch 29/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0677 - f1_score: 0.4334\n",
      "Epoch 30/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0674 - f1_score: 0.4379\n",
      "Epoch 31/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0671 - f1_score: 0.4406\n",
      "Epoch 32/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0668 - f1_score: 0.4436\n",
      "Epoch 33/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0666 - f1_score: 0.4465\n",
      "Epoch 34/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0663 - f1_score: 0.4498\n",
      "Epoch 35/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0660 - f1_score: 0.4526\n",
      "Epoch 36/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0658 - f1_score: 0.4552\n",
      "Epoch 37/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0656 - f1_score: 0.4580\n",
      "Epoch 38/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0653 - f1_score: 0.4607\n",
      "Epoch 39/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0650 - f1_score: 0.4630\n",
      "Epoch 40/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0649 - f1_score: 0.4657\n",
      "Epoch 41/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0646 - f1_score: 0.4677\n",
      "Epoch 42/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0644 - f1_score: 0.4708\n",
      "Epoch 43/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0642 - f1_score: 0.4732\n",
      "Epoch 44/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0641 - f1_score: 0.4748\n",
      "Epoch 45/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0638 - f1_score: 0.4772\n",
      "Epoch 46/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0637 - f1_score: 0.4791\n",
      "Epoch 47/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0635 - f1_score: 0.4813\n",
      "Epoch 48/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0633 - f1_score: 0.4833\n",
      "Epoch 49/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0630 - f1_score: 0.4862\n",
      "Epoch 50/50\n",
      "1304/1304 [==============================] - 2s 2ms/step - loss: 0.0629 - f1_score: 0.4866\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "model = train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231/231 [==============================] - 0s 688us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation - Bilogical Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.35      0.45       551\n",
      "           1       0.64      0.46      0.53       943\n",
      "           2       0.60      0.38      0.47       401\n",
      "           3       0.08      0.02      0.03        52\n",
      "           4       0.61      0.42      0.50      1149\n",
      "           5       0.63      0.49      0.55      1400\n",
      "           6       0.63      0.45      0.53      1245\n",
      "           7       0.67      0.59      0.63      2080\n",
      "           8       0.62      0.53      0.57      1728\n",
      "           9       0.71      0.66      0.69      2513\n",
      "          10       0.32      0.08      0.13        95\n",
      "          11       0.36      0.21      0.26       341\n",
      "          12       0.71      0.91      0.80      4935\n",
      "          13       0.29      0.18      0.22       266\n",
      "          14       1.00      1.00      1.00      7362\n",
      "          15       0.63      0.44      0.52       747\n",
      "          16       0.65      0.36      0.47       714\n",
      "          17       0.61      0.45      0.51       888\n",
      "          18       0.64      0.56      0.60      1972\n",
      "          19       0.29      0.08      0.13        99\n",
      "          20       0.62      0.45      0.52      1205\n",
      "          21       0.61      0.47      0.53       864\n",
      "          22       0.62      0.46      0.53       990\n",
      "          23       0.25      0.12      0.16       269\n",
      "          24       0.70      0.66      0.68      2320\n",
      "          25       0.32      0.14      0.19       176\n",
      "          26       0.43      0.03      0.05       399\n",
      "          27       0.70      0.22      0.33       609\n",
      "          28       1.00      0.03      0.05        36\n",
      "          29       0.70      0.23      0.34       501\n",
      "          30       0.50      0.03      0.06        31\n",
      "          31       0.67      0.03      0.06        64\n",
      "          32       0.69      0.19      0.30       531\n",
      "          33       0.00      0.00      0.00        43\n",
      "          34       0.46      0.08      0.13       786\n",
      "          35       0.38      0.03      0.06       280\n",
      "          36       0.66      0.14      0.23       863\n",
      "          37       0.45      0.03      0.06       295\n",
      "          38       0.39      0.05      0.08       610\n",
      "          39       0.52      0.22      0.31      1422\n",
      "          40       0.48      0.14      0.22      1147\n",
      "          41       0.47      0.06      0.11       561\n",
      "          42       0.61      0.41      0.49      2502\n",
      "          43       0.69      0.23      0.34       501\n",
      "          44       0.67      0.14      0.23       228\n",
      "          45       1.00      0.04      0.07        56\n",
      "          46       1.00      0.02      0.04       147\n",
      "          47       0.55      0.09      0.15       298\n",
      "          48       0.57      0.04      0.07       211\n",
      "          49       0.53      0.03      0.06       240\n",
      "          50       0.30      0.03      0.05       257\n",
      "          51       1.00      0.01      0.02        79\n",
      "          52       0.50      0.02      0.04        96\n",
      "          53       1.00      0.02      0.04        92\n",
      "          54       0.50      0.02      0.03       111\n",
      "          55       0.52      0.07      0.12       413\n",
      "          56       0.57      0.03      0.06       137\n",
      "          57       1.00      0.02      0.05        41\n",
      "          58       0.50      0.03      0.06        33\n",
      "          59       0.27      0.07      0.11       196\n",
      "          60       1.00      0.02      0.05        42\n",
      "          61       1.00      0.02      0.05        42\n",
      "          62       0.26      0.05      0.08       185\n",
      "          63       1.00      0.02      0.05        41\n",
      "          64       0.00      0.00      0.00        66\n",
      "          65       0.46      0.05      0.09       233\n",
      "          66       0.48      0.38      0.42      1136\n",
      "          67       0.56      0.55      0.55      2054\n",
      "          68       1.00      0.02      0.05        42\n",
      "          69       0.55      0.54      0.54      1990\n",
      "          70       0.00      0.00      0.00        63\n",
      "          71       0.53      0.45      0.48      1469\n",
      "          72       0.55      0.52      0.53      1889\n",
      "          73       0.48      0.31      0.38       790\n",
      "          74       0.00      0.00      0.00        45\n",
      "          75       0.00      0.00      0.00        37\n",
      "          76       0.40      0.16      0.22       557\n",
      "          77       0.45      0.03      0.06       159\n",
      "          78       0.54      0.15      0.24      1235\n",
      "          79       0.69      0.68      0.69      3271\n",
      "          80       0.69      0.70      0.70      3424\n",
      "          81       0.67      0.64      0.66      2946\n",
      "          82       0.21      0.02      0.04       149\n",
      "          83       0.19      0.02      0.04       146\n",
      "          84       0.50      0.24      0.32      1159\n",
      "          85       0.51      0.23      0.32      1291\n",
      "          86       0.32      0.03      0.05       239\n",
      "          87       0.26      0.02      0.04       256\n",
      "          88       0.61      0.52      0.56       915\n",
      "          89       0.38      0.24      0.29        76\n",
      "          90       0.63      0.32      0.43        37\n",
      "          91       0.32      0.19      0.24        67\n",
      "          92       0.28      0.15      0.20        65\n",
      "          93       0.66      0.36      0.46       135\n",
      "          94       0.41      0.23      0.29        83\n",
      "          95       0.65      0.31      0.42       114\n",
      "          96       0.63      0.40      0.49       163\n",
      "          97       0.49      0.36      0.42       209\n",
      "          98       0.60      0.50      0.54       973\n",
      "          99       0.59      0.50      0.54      1147\n",
      "         100       0.50      0.36      0.42      1472\n",
      "         101       0.52      0.37      0.43      1563\n",
      "         102       0.47      0.29      0.36       778\n",
      "         103       0.63      0.34      0.44        93\n",
      "         104       0.66      0.40      0.50       230\n",
      "         105       0.61      0.37      0.46        76\n",
      "         106       0.62      0.37      0.47        75\n",
      "         107       0.58      0.33      0.42        96\n",
      "         108       0.59      0.27      0.38       153\n",
      "         109       0.61      0.39      0.48        69\n",
      "         110       0.47      0.27      0.35       374\n",
      "         111       0.44      0.26      0.33       359\n",
      "         112       0.45      0.35      0.39       112\n",
      "         113       0.44      0.31      0.37       337\n",
      "         114       0.43      0.37      0.39       101\n",
      "         115       0.55      0.36      0.44       691\n",
      "         116       0.56      0.41      0.47      1135\n",
      "         117       0.45      0.29      0.35       402\n",
      "         118       0.60      0.07      0.13       125\n",
      "         119       0.00      0.00      0.00        36\n",
      "         120       0.00      0.00      0.00        57\n",
      "         121       0.55      0.26      0.35       142\n",
      "         122       0.47      0.09      0.15       639\n",
      "         123       0.62      0.04      0.08       241\n",
      "         124       0.42      0.08      0.14       529\n",
      "         125       0.00      0.00      0.00        47\n",
      "         126       0.54      0.07      0.13       416\n",
      "         127       0.72      0.19      0.31        67\n",
      "         128       0.68      0.51      0.58       242\n",
      "         129       0.62      0.20      0.30        41\n",
      "         130       0.61      0.25      0.35       521\n",
      "         131       0.62      0.47      0.53      1641\n",
      "         132       0.64      0.45      0.53      1270\n",
      "         133       0.61      0.18      0.28       318\n",
      "         134       0.62      0.48      0.54       766\n",
      "         135       0.58      0.23      0.33       676\n",
      "         136       0.61      0.47      0.53      1523\n",
      "         137       0.63      0.46      0.53      1300\n",
      "         138       0.59      0.42      0.49      1203\n",
      "         139       0.62      0.48      0.54       762\n",
      "         140       0.61      0.25      0.36       508\n",
      "         141       0.52      0.18      0.27       484\n",
      "         142       0.58      0.42      0.49      1256\n",
      "         143       0.56      0.23      0.33       618\n",
      "         144       0.64      0.46      0.53      1314\n",
      "         145       0.64      0.46      0.54      1233\n",
      "         146       0.60      0.16      0.25       342\n",
      "         147       0.61      0.19      0.29       286\n",
      "         148       0.63      0.47      0.54      1483\n",
      "         149       0.61      0.46      0.52       916\n",
      "         150       0.60      0.24      0.34       630\n",
      "         151       0.61      0.45      0.52       856\n",
      "         152       0.61      0.23      0.34       533\n",
      "         153       0.61      0.19      0.29       284\n",
      "         154       0.00      0.00      0.00       102\n",
      "         155       0.36      0.02      0.03       582\n",
      "         156       0.86      0.04      0.08       151\n",
      "         157       1.00      0.02      0.04        55\n",
      "         158       0.00      0.00      0.00        56\n",
      "         159       0.00      0.00      0.00        51\n",
      "         160       0.51      0.03      0.06       634\n",
      "         161       0.67      0.02      0.03       117\n",
      "         162       1.00      0.03      0.05        79\n",
      "         163       0.40      0.14      0.21       316\n",
      "         164       0.36      0.11      0.17       159\n",
      "         165       0.51      0.33      0.40       853\n",
      "         166       0.39      0.10      0.16       191\n",
      "         167       0.25      0.03      0.05        33\n",
      "         168       0.37      0.06      0.11       373\n",
      "         169       0.26      0.04      0.07       181\n",
      "         170       0.00      0.00      0.00       113\n",
      "         171       0.67      0.03      0.05        73\n",
      "         172       0.41      0.15      0.22       301\n",
      "         173       0.43      0.24      0.31        84\n",
      "         174       0.48      0.26      0.34        97\n",
      "         175       0.41      0.16      0.23       308\n",
      "         176       0.00      0.00      0.00        56\n",
      "         177       0.45      0.13      0.20       141\n",
      "         178       0.45      0.13      0.20       128\n",
      "         179       0.54      0.21      0.30       296\n",
      "         180       0.31      0.04      0.07       298\n",
      "         181       0.42      0.05      0.09       168\n",
      "         182       0.17      0.02      0.04        45\n",
      "         183       0.50      0.01      0.03        71\n",
      "         184       0.68      0.10      0.17       136\n",
      "         185       0.33      0.03      0.06        61\n",
      "         186       0.31      0.04      0.07       274\n",
      "         187       0.35      0.05      0.08       608\n",
      "         188       0.40      0.03      0.05       238\n",
      "         189       0.00      0.00      0.00       180\n",
      "         190       0.00      0.00      0.00        47\n",
      "         191       0.54      0.27      0.36      1543\n",
      "         192       0.00      0.00      0.00        76\n",
      "         193       0.00      0.00      0.00       103\n",
      "         194       0.40      0.07      0.11       578\n",
      "         195       1.00      0.08      0.15        51\n",
      "         196       0.50      0.05      0.09        98\n",
      "         197       0.50      0.09      0.15       102\n",
      "         198       1.00      0.06      0.11        34\n",
      "         199       0.53      0.28      0.36       245\n",
      "         200       0.38      0.04      0.07       135\n",
      "         201       0.54      0.27      0.36        49\n",
      "         202       0.45      0.28      0.34       890\n",
      "         203       0.64      0.11      0.19        82\n",
      "         204       0.54      0.27      0.36        49\n",
      "         205       0.46      0.27      0.34       901\n",
      "         206       0.43      0.08      0.14        37\n",
      "         207       0.54      0.21      0.30       172\n",
      "         208       0.27      0.09      0.13       101\n",
      "         209       0.61      0.13      0.21       319\n",
      "         210       0.62      0.19      0.29       550\n",
      "         211       0.60      0.04      0.08        70\n",
      "         212       0.60      0.04      0.08        72\n",
      "         213       0.50      0.06      0.10       108\n",
      "         214       0.00      0.00      0.00        39\n",
      "         215       0.00      0.00      0.00        43\n",
      "         216       0.00      0.00      0.00        73\n",
      "         217       0.00      0.00      0.00        38\n",
      "         218       0.00      0.00      0.00       136\n",
      "         219       0.42      0.29      0.35       519\n",
      "         220       0.40      0.01      0.02       213\n",
      "         221       0.00      0.00      0.00       149\n",
      "         222       0.63      0.17      0.27       376\n",
      "         223       1.00      0.02      0.03        59\n",
      "         224       0.32      0.04      0.07       240\n",
      "         225       0.47      0.12      0.19       929\n",
      "         226       0.49      0.13      0.21       802\n",
      "         227       0.25      0.02      0.03       166\n",
      "         228       0.46      0.11      0.17       715\n",
      "         229       0.27      0.01      0.02       230\n",
      "         230       0.00      0.00      0.00        39\n",
      "         231       0.41      0.15      0.22       699\n",
      "         232       0.00      0.00      0.00        45\n",
      "         233       0.00      0.00      0.00        94\n",
      "         234       0.43      0.15      0.23       486\n",
      "         235       0.40      0.15      0.22       673\n",
      "         236       0.80      0.03      0.06       128\n",
      "         237       0.80      0.03      0.06       125\n",
      "         238       0.67      0.04      0.07       101\n",
      "         239       0.50      0.06      0.11        95\n",
      "         240       0.42      0.05      0.10        92\n",
      "         241       0.00      0.00      0.00        40\n",
      "         242       0.41      0.21      0.27       323\n",
      "         243       0.41      0.22      0.28       357\n",
      "         244       0.63      0.09      0.16       192\n",
      "         245       0.54      0.06      0.10       243\n",
      "         246       0.00      0.00      0.00        32\n",
      "         247       0.39      0.13      0.19       110\n",
      "         248       0.25      0.01      0.02       108\n",
      "         249       0.48      0.08      0.14       127\n",
      "         250       0.47      0.05      0.10       165\n",
      "         251       0.00      0.00      0.00       211\n",
      "         252       0.60      0.03      0.05       319\n",
      "         253       0.50      0.05      0.09       212\n",
      "         254       0.41      0.14      0.20       103\n",
      "         255       0.52      0.15      0.23       562\n",
      "         256       0.33      0.01      0.01       147\n",
      "         257       0.42      0.11      0.18        88\n",
      "         258       0.33      0.00      0.01       234\n",
      "         259       0.50      0.02      0.03       130\n",
      "         260       0.59      0.12      0.20        84\n",
      "         261       0.00      0.00      0.00        84\n",
      "         262       0.36      0.11      0.17        90\n",
      "         263       0.00      0.00      0.00       115\n",
      "         264       0.00      0.00      0.00        90\n",
      "         265       0.54      0.14      0.23        49\n",
      "         266       0.00      0.00      0.00        85\n",
      "         267       0.33      0.01      0.02        98\n",
      "         268       0.53      0.24      0.34      1366\n",
      "         269       0.52      0.40      0.46       442\n",
      "         270       0.57      0.12      0.20        33\n",
      "         271       0.67      0.03      0.06        64\n",
      "         272       0.50      0.02      0.04       104\n",
      "         273       0.67      0.01      0.02       164\n",
      "         274       0.43      0.16      0.23       371\n",
      "         275       0.54      0.30      0.39       293\n",
      "         276       0.52      0.31      0.39       318\n",
      "         277       0.62      0.17      0.27       104\n",
      "         278       0.56      0.15      0.24       120\n",
      "         279       0.45      0.18      0.26       632\n",
      "         280       0.25      0.03      0.05        39\n",
      "         281       0.38      0.07      0.12        44\n",
      "         282       0.56      0.16      0.24        32\n",
      "         283       0.62      0.11      0.19        45\n",
      "         284       0.45      0.12      0.19       196\n",
      "         285       0.50      0.12      0.19        51\n",
      "         286       0.53      0.19      0.28        91\n",
      "         287       0.20      0.04      0.06       129\n",
      "         288       0.58      0.38      0.46       339\n",
      "         289       0.49      0.23      0.31        93\n",
      "         290       0.59      0.36      0.44       360\n",
      "         291       0.66      0.51      0.57       651\n",
      "         292       0.69      0.33      0.44       128\n",
      "         293       0.58      0.35      0.44       356\n",
      "         294       0.40      0.09      0.15       797\n",
      "         295       0.47      0.05      0.08       150\n",
      "         296       0.36      0.03      0.05       278\n",
      "         297       0.55      0.10      0.16        63\n",
      "         298       0.43      0.07      0.12       125\n",
      "         299       0.38      0.04      0.08       113\n",
      "         300       0.40      0.12      0.18       221\n",
      "         301       0.33      0.03      0.05       221\n",
      "         302       0.57      0.29      0.39        41\n",
      "         303       0.58      0.33      0.42        33\n",
      "         304       0.00      0.00      0.00        74\n",
      "         305       1.00      0.02      0.05        41\n",
      "         306       0.57      0.09      0.16        44\n",
      "         307       0.58      0.29      0.38       230\n",
      "         308       0.37      0.04      0.07       389\n",
      "         309       0.00      0.00      0.00       129\n",
      "         310       0.00      0.00      0.00        59\n",
      "         311       0.00      0.00      0.00       191\n",
      "         312       0.00      0.00      0.00       163\n",
      "         313       1.00      0.02      0.04        46\n",
      "         314       0.00      0.00      0.00       153\n",
      "         315       0.00      0.00      0.00        98\n",
      "         316       0.48      0.29      0.36       308\n",
      "         317       0.65      0.05      0.09       217\n",
      "         318       0.47      0.33      0.39       626\n",
      "         319       1.00      0.03      0.06        33\n",
      "         320       0.49      0.08      0.14       514\n",
      "         321       0.26      0.08      0.12       105\n",
      "         322       0.00      0.00      0.00        51\n",
      "         323       0.33      0.01      0.03       218\n",
      "         324       0.00      0.00      0.00       173\n",
      "         325       0.00      0.00      0.00        82\n",
      "         326       0.00      0.00      0.00        57\n",
      "         327       0.00      0.00      0.00        95\n",
      "         328       0.45      0.03      0.05       348\n",
      "         329       0.25      0.01      0.01       166\n",
      "         330       0.46      0.29      0.36       412\n",
      "         331       0.43      0.04      0.07       423\n",
      "         332       0.00      0.00      0.00        92\n",
      "         333       0.00      0.00      0.00        44\n",
      "         334       0.00      0.00      0.00        54\n",
      "         335       0.00      0.00      0.00        68\n",
      "         336       0.51      0.21      0.30       845\n",
      "         337       0.00      0.00      0.00        44\n",
      "         338       0.46      0.18      0.26       639\n",
      "         339       0.38      0.08      0.13       385\n",
      "         340       0.00      0.00      0.00        44\n",
      "         341       0.33      0.02      0.04       266\n",
      "         342       0.50      0.21      0.29       771\n",
      "         343       0.00      0.00      0.00       197\n",
      "         344       0.25      0.01      0.02       175\n",
      "         345       0.00      0.00      0.00       109\n",
      "         346       0.33      0.01      0.01       154\n",
      "         347       0.12      0.01      0.02        81\n",
      "         348       0.57      0.14      0.23       298\n",
      "         349       0.00      0.00      0.00        34\n",
      "         350       0.00      0.00      0.00        86\n",
      "         351       0.18      0.02      0.04       279\n",
      "         352       0.17      0.02      0.04       280\n",
      "         353       0.24      0.03      0.06       287\n",
      "         354       0.36      0.08      0.13       545\n",
      "         355       0.12      0.01      0.02       147\n",
      "         356       0.35      0.06      0.11       367\n",
      "         357       0.17      0.02      0.03       233\n",
      "         358       0.39      0.09      0.15       654\n",
      "         359       0.50      0.01      0.02       107\n",
      "         360       0.40      0.10      0.16       653\n",
      "         361       0.64      0.45      0.52        47\n",
      "         362       0.57      0.42      0.48        50\n",
      "         363       0.71      0.27      0.39       146\n",
      "         364       0.76      0.35      0.48        79\n",
      "         365       0.74      0.42      0.54        62\n",
      "         366       0.72      0.49      0.58        43\n",
      "         367       0.58      0.42      0.49        50\n",
      "         368       0.70      0.47      0.56        45\n",
      "         369       0.68      0.32      0.43       125\n",
      "         370       0.65      0.42      0.51        52\n",
      "         371       0.49      0.05      0.09       333\n",
      "         372       0.51      0.21      0.30       626\n",
      "         373       0.51      0.21      0.30       464\n",
      "         374       0.50      0.24      0.32       429\n",
      "         375       0.50      0.21      0.30       622\n",
      "         376       0.52      0.22      0.31       596\n",
      "         377       0.50      0.20      0.29       769\n",
      "         378       0.56      0.33      0.42       404\n",
      "         379       0.49      0.26      0.34       391\n",
      "         380       0.49      0.27      0.34       392\n",
      "         381       0.45      0.24      0.32       246\n",
      "         382       0.00      0.00      0.00        52\n",
      "         383       0.00      0.00      0.00        73\n",
      "         384       0.00      0.00      0.00        62\n",
      "         385       0.71      0.18      0.29       158\n",
      "         386       0.62      0.14      0.23       177\n",
      "         387       0.48      0.09      0.16       158\n",
      "         388       0.44      0.16      0.24       345\n",
      "         389       0.46      0.20      0.28       257\n",
      "         390       0.43      0.17      0.24       291\n",
      "         391       0.31      0.04      0.06       113\n",
      "         392       0.39      0.16      0.23       359\n",
      "         393       0.37      0.15      0.21       462\n",
      "         394       0.33      0.04      0.08        92\n",
      "         395       0.38      0.17      0.24       344\n",
      "         396       0.40      0.03      0.05        70\n",
      "         397       0.25      0.01      0.01       144\n",
      "         398       0.00      0.00      0.00        47\n",
      "         399       0.00      0.00      0.00       122\n",
      "         400       1.00      0.02      0.04        49\n",
      "         401       0.43      0.07      0.12        87\n",
      "         402       0.60      0.06      0.11       198\n",
      "         403       0.50      0.02      0.04        51\n",
      "         404       0.00      0.00      0.00        80\n",
      "         405       0.00      0.00      0.00       223\n",
      "         406       0.00      0.00      0.00        84\n",
      "         407       0.50      0.04      0.08       187\n",
      "         408       0.27      0.09      0.14        33\n",
      "         409       0.47      0.12      0.19        69\n",
      "         410       0.38      0.12      0.18        26\n",
      "         411       0.54      0.13      0.20       247\n",
      "         412       0.43      0.11      0.17        28\n",
      "         413       0.68      0.12      0.20       127\n",
      "         414       0.66      0.46      0.54       377\n",
      "         415       0.74      0.68      0.71        41\n",
      "         416       0.67      0.50      0.57        62\n",
      "         417       0.84      0.49      0.62        77\n",
      "         418       0.68      0.40      0.51       310\n",
      "         419       0.53      0.37      0.44       211\n",
      "         420       0.57      0.68      0.62        31\n",
      "         421       0.00      0.00      0.00        52\n",
      "         422       0.33      0.02      0.03        63\n",
      "         423       0.33      0.03      0.05        35\n",
      "         424       0.33      0.02      0.05        41\n",
      "         425       0.00      0.00      0.00        69\n",
      "         426       0.00      0.00      0.00        44\n",
      "         427       0.43      0.14      0.21        72\n",
      "         428       0.48      0.17      0.25        84\n",
      "         429       0.52      0.22      0.31       106\n",
      "         430       0.47      0.23      0.30        93\n",
      "         431       0.00      0.00      0.00        54\n",
      "         432       0.00      0.00      0.00       174\n",
      "         433       0.55      0.25      0.34        93\n",
      "         434       0.62      0.19      0.29       470\n",
      "         435       0.60      0.14      0.23       242\n",
      "         436       0.63      0.22      0.33       143\n",
      "         437       0.56      0.13      0.21       252\n",
      "         438       0.00      0.00      0.00        40\n",
      "         439       0.00      0.00      0.00        51\n",
      "         440       0.00      0.00      0.00        87\n",
      "         441       0.80      0.12      0.21        34\n",
      "         442       0.67      0.04      0.08        48\n",
      "         443       0.14      0.02      0.04        47\n",
      "         444       0.50      0.05      0.10        57\n",
      "         445       0.72      0.14      0.24        90\n",
      "         446       0.00      0.00      0.00        35\n",
      "         447       0.67      0.06      0.11        32\n",
      "         448       0.00      0.00      0.00        71\n",
      "         449       0.45      0.15      0.23       405\n",
      "         450       0.50      0.12      0.20       233\n",
      "         451       0.00      0.00      0.00       113\n",
      "         452       0.41      0.16      0.23       184\n",
      "         453       0.56      0.07      0.12       145\n",
      "         454       0.41      0.20      0.27       267\n",
      "         455       0.00      0.00      0.00        38\n",
      "         456       0.33      0.02      0.04        53\n",
      "         457       0.52      0.19      0.28       135\n",
      "         458       0.41      0.15      0.21       240\n",
      "         459       0.43      0.21      0.28       280\n",
      "         460       0.40      0.21      0.27       295\n",
      "         461       0.22      0.04      0.07        95\n",
      "         462       0.32      0.05      0.09       185\n",
      "         463       0.45      0.18      0.25        79\n",
      "         464       0.46      0.27      0.34        49\n",
      "         465       0.45      0.27      0.34        55\n",
      "         466       0.50      0.21      0.29        67\n",
      "         467       0.50      0.11      0.18       157\n",
      "         468       1.00      0.03      0.06        32\n",
      "         469       1.00      0.03      0.05        37\n",
      "         470       0.60      0.18      0.28       312\n",
      "         471       0.36      0.04      0.07       102\n",
      "         472       0.57      0.04      0.07       105\n",
      "         473       0.38      0.07      0.12        42\n",
      "         474       0.44      0.02      0.04       182\n",
      "         475       0.38      0.04      0.08        71\n",
      "         476       0.33      0.03      0.06        89\n",
      "         477       0.31      0.03      0.06       158\n",
      "         478       0.36      0.04      0.07       123\n",
      "         479       0.43      0.03      0.05       112\n",
      "         480       0.36      0.03      0.06       159\n",
      "         481       0.33      0.03      0.06        89\n",
      "         482       0.38      0.05      0.08       132\n",
      "         483       0.33      0.04      0.07        77\n",
      "         484       0.25      0.01      0.03       142\n",
      "         485       0.33      0.04      0.07       276\n",
      "         486       0.50      0.02      0.05       210\n",
      "         487       1.00      0.01      0.03        71\n",
      "         488       0.56      0.19      0.28        54\n",
      "         489       0.67      0.28      0.39        36\n",
      "         490       0.55      0.22      0.32       255\n",
      "         491       0.48      0.31      0.37       154\n",
      "         492       0.36      0.13      0.19        79\n",
      "         493       0.68      0.34      0.46        87\n",
      "         494       0.63      0.27      0.38       189\n",
      "         495       0.59      0.34      0.43        47\n",
      "         496       0.56      0.19      0.29        94\n",
      "         497       0.75      0.25      0.37        61\n",
      "         498       0.54      0.23      0.32        66\n",
      "         499       0.57      0.30      0.40        79\n",
      "         500       0.51      0.30      0.38       399\n",
      "         501       0.53      0.22      0.31       216\n",
      "         502       0.37      0.20      0.26       121\n",
      "         503       0.55      0.27      0.36        45\n",
      "         504       0.40      0.06      0.11        63\n",
      "         505       0.41      0.05      0.08       232\n",
      "         506       0.22      0.02      0.04       102\n",
      "         507       0.67      0.04      0.08        46\n",
      "         508       1.00      0.02      0.03        64\n",
      "         509       0.50      0.11      0.18        75\n",
      "         510       0.56      0.14      0.22        37\n",
      "         511       0.00      0.00      0.00        83\n",
      "         512       0.33      0.10      0.15       132\n",
      "         513       0.50      0.06      0.10        70\n",
      "         514       0.62      0.09      0.15        58\n",
      "         515       0.36      0.02      0.04       184\n",
      "         516       0.00      0.00      0.00        28\n",
      "         517       0.50      0.08      0.14        74\n",
      "         518       0.60      0.32      0.41        38\n",
      "         519       0.48      0.20      0.28       225\n",
      "         520       0.46      0.22      0.29       116\n",
      "         521       0.52      0.26      0.35       157\n",
      "         522       0.51      0.25      0.34        99\n",
      "         523       0.00      0.00      0.00        96\n",
      "         524       0.45      0.22      0.30       135\n",
      "         525       0.50      0.03      0.06        62\n",
      "         526       0.25      0.01      0.02        87\n",
      "         527       0.00      0.00      0.00        69\n",
      "         528       0.55      0.08      0.14       134\n",
      "         529       0.63      0.10      0.17       126\n",
      "         530       0.43      0.09      0.15        34\n",
      "         531       0.60      0.27      0.37       103\n",
      "         532       0.75      0.16      0.26       133\n",
      "         533       0.35      0.02      0.04       259\n",
      "         534       0.41      0.03      0.06       231\n",
      "         535       0.40      0.02      0.04        98\n",
      "         536       0.47      0.02      0.04       306\n",
      "         537       0.35      0.02      0.04       260\n",
      "         538       0.67      0.03      0.05        73\n",
      "         539       1.00      0.03      0.06        35\n",
      "         540       0.00      0.00      0.00       201\n",
      "         541       1.00      0.01      0.03        70\n",
      "         542       0.00      0.00      0.00       148\n",
      "         543       0.50      0.02      0.05        42\n",
      "         544       0.33      0.03      0.05        36\n",
      "         545       0.00      0.00      0.00        37\n",
      "         546       0.63      0.36      0.45       132\n",
      "         547       0.83      0.06      0.11        84\n",
      "         548       0.80      0.04      0.07       102\n",
      "         549       0.65      0.06      0.11       223\n",
      "         550       0.71      0.06      0.11        87\n",
      "         551       0.00      0.00      0.00        49\n",
      "         552       0.58      0.08      0.13       146\n",
      "         553       0.00      0.00      0.00        65\n",
      "         554       0.83      0.08      0.14        64\n",
      "         555       0.00      0.00      0.00       100\n",
      "         556       0.33      0.02      0.03        61\n",
      "         557       1.00      0.02      0.04        44\n",
      "         558       0.26      0.04      0.07       125\n",
      "         559       1.00      0.03      0.06        65\n",
      "         560       0.31      0.06      0.10       136\n",
      "         561       0.26      0.04      0.07       125\n",
      "         562       0.00      0.00      0.00        35\n",
      "         563       0.17      0.02      0.03       107\n",
      "         564       0.00      0.00      0.00        45\n",
      "         565       0.00      0.00      0.00        39\n",
      "         566       0.54      0.12      0.20       182\n",
      "         567       0.67      0.02      0.03       123\n",
      "         568       0.50      0.03      0.06        32\n",
      "         569       1.00      0.05      0.09        42\n",
      "         570       1.00      0.05      0.10        40\n",
      "         571       1.00      0.03      0.05        40\n",
      "         572       0.53      0.17      0.26       150\n",
      "         573       0.46      0.19      0.27       117\n",
      "         574       0.50      0.19      0.27       144\n",
      "         575       0.46      0.18      0.26       142\n",
      "         576       0.43      0.18      0.25       107\n",
      "         577       0.50      0.19      0.27       145\n",
      "         578       0.00      0.00      0.00        23\n",
      "         579       0.69      0.16      0.26        57\n",
      "         580       0.69      0.13      0.22        69\n",
      "         581       0.33      0.02      0.04        52\n",
      "         582       0.50      0.01      0.02       121\n",
      "         583       0.00      0.00      0.00        23\n",
      "         584       0.21      0.01      0.03       201\n",
      "         585       0.00      0.00      0.00        37\n",
      "         586       0.00      0.00      0.00       115\n",
      "         587       0.00      0.00      0.00        47\n",
      "         588       0.70      0.16      0.25        45\n",
      "         589       1.00      0.05      0.10        60\n",
      "         590       0.54      0.05      0.09       139\n",
      "         591       0.00      0.00      0.00        39\n",
      "         592       0.00      0.00      0.00        58\n",
      "         593       0.39      0.08      0.13       210\n",
      "         594       0.38      0.07      0.12       213\n",
      "         595       0.00      0.00      0.00        65\n",
      "         596       0.00      0.00      0.00        56\n",
      "         597       0.45      0.06      0.11        84\n",
      "         598       0.50      0.06      0.11        79\n",
      "         599       0.00      0.00      0.00        76\n",
      "         600       0.00      0.00      0.00        55\n",
      "         601       0.00      0.00      0.00        67\n",
      "         602       0.00      0.00      0.00        48\n",
      "         603       0.33      0.02      0.04       104\n",
      "         604       0.00      0.00      0.00        72\n",
      "         605       0.27      0.06      0.10        69\n",
      "         606       0.71      0.06      0.12        78\n",
      "         607       0.00      0.00      0.00        66\n",
      "         608       1.00      0.03      0.05        39\n",
      "         609       0.00      0.00      0.00        43\n",
      "         610       0.00      0.00      0.00        48\n",
      "         611       0.00      0.00      0.00        83\n",
      "         612       0.00      0.00      0.00        94\n",
      "         613       0.00      0.00      0.00        44\n",
      "         614       0.00      0.00      0.00        79\n",
      "         615       1.00      0.01      0.02       111\n",
      "         616       0.00      0.00      0.00        43\n",
      "         617       0.25      0.02      0.03       292\n",
      "         618       0.00      0.00      0.00        40\n",
      "         619       0.49      0.16      0.24       147\n",
      "         620       0.56      0.21      0.30       216\n",
      "         621       0.52      0.13      0.21        84\n",
      "         622       0.51      0.29      0.37       156\n",
      "         623       0.47      0.35      0.40       309\n",
      "         624       0.67      0.08      0.15        24\n",
      "         625       0.80      0.08      0.14       102\n",
      "         626       0.44      0.28      0.34       181\n",
      "         627       0.67      0.08      0.15        24\n",
      "         628       0.69      0.14      0.23        81\n",
      "         629       0.81      0.14      0.23        96\n",
      "         630       1.00      0.01      0.02        94\n",
      "         631       0.50      0.09      0.16        64\n",
      "         632       0.42      0.06      0.11        81\n",
      "         633       0.44      0.04      0.07       182\n",
      "         634       0.00      0.00      0.00        35\n",
      "         635       0.00      0.00      0.00        41\n",
      "         636       0.00      0.00      0.00       106\n",
      "         637       0.00      0.00      0.00        31\n",
      "         638       0.40      0.02      0.05        83\n",
      "         639       0.40      0.02      0.05        83\n",
      "         640       0.00      0.00      0.00        51\n",
      "         641       0.20      0.02      0.03       215\n",
      "         642       0.00      0.00      0.00        34\n",
      "         643       0.75      0.03      0.06        92\n",
      "         644       0.00      0.00      0.00        22\n",
      "         645       0.55      0.24      0.33       131\n",
      "         646       0.58      0.17      0.27       174\n",
      "         647       0.61      0.18      0.28       103\n",
      "         648       0.63      0.15      0.24       128\n",
      "         649       0.69      0.17      0.27        53\n",
      "         650       0.50      0.08      0.13        53\n",
      "         651       0.50      0.27      0.35        82\n",
      "         652       0.00      0.00      0.00        36\n",
      "         653       0.20      0.01      0.01       199\n",
      "         654       0.55      0.15      0.23        81\n",
      "         655       0.48      0.24      0.32        55\n",
      "         656       0.63      0.13      0.22        89\n",
      "         657       0.32      0.17      0.22        41\n",
      "         658       0.44      0.26      0.33        57\n",
      "         659       0.31      0.19      0.24        42\n",
      "         660       0.40      0.18      0.25        56\n",
      "         661       0.49      0.26      0.34        73\n",
      "         662       0.50      0.27      0.35        77\n",
      "         663       0.48      0.24      0.32        54\n",
      "         664       1.00      0.02      0.04        46\n",
      "         665       0.20      0.02      0.04       102\n",
      "         666       0.67      0.06      0.12        31\n",
      "         667       0.33      0.02      0.03        56\n",
      "         668       0.40      0.04      0.07        50\n",
      "         669       0.25      0.04      0.06        57\n",
      "         670       0.00      0.00      0.00        43\n",
      "         671       0.00      0.00      0.00        45\n",
      "         672       0.40      0.02      0.04        99\n",
      "         673       0.50      0.13      0.20        71\n",
      "         674       0.50      0.15      0.23        61\n",
      "         675       0.50      0.15      0.23        61\n",
      "         676       0.56      0.14      0.23        64\n",
      "         677       0.25      0.09      0.13        33\n",
      "         678       0.20      0.05      0.07        44\n",
      "         679       0.56      0.26      0.35        39\n",
      "         680       0.70      0.34      0.46        92\n",
      "         681       0.58      0.22      0.31       176\n",
      "         682       0.61      0.19      0.29        74\n",
      "         683       0.81      0.29      0.43        58\n",
      "         684       0.80      0.25      0.38        48\n",
      "         685       0.59      0.22      0.32        74\n",
      "         686       0.59      0.15      0.25       123\n",
      "         687       0.27      0.06      0.10        65\n",
      "         688       0.45      0.07      0.12        74\n",
      "         689       0.43      0.35      0.39        68\n",
      "         690       0.42      0.36      0.39        69\n",
      "         691       0.39      0.32      0.35        91\n",
      "         692       0.33      0.03      0.05        72\n",
      "         693       0.00      0.00      0.00        35\n",
      "         694       0.00      0.00      0.00        49\n",
      "         695       0.35      0.03      0.05       236\n",
      "         696       0.00      0.00      0.00        50\n",
      "         697       0.50      0.29      0.37       121\n",
      "         698       0.49      0.31      0.38        90\n",
      "         699       0.73      0.17      0.27        48\n",
      "         700       0.45      0.17      0.25       161\n",
      "         701       0.65      0.25      0.36        61\n",
      "         702       0.65      0.25      0.36        61\n",
      "         703       0.50      0.03      0.06        33\n",
      "         704       0.00      0.00      0.00        33\n",
      "         705       0.29      0.04      0.07        47\n",
      "         706       0.00      0.00      0.00        28\n",
      "         707       1.00      0.04      0.08        51\n",
      "         708       0.67      0.02      0.03       132\n",
      "         709       0.00      0.00      0.00        61\n",
      "         710       0.59      0.30      0.39        81\n",
      "         711       0.00      0.00      0.00        31\n",
      "         712       0.00      0.00      0.00        61\n",
      "         713       0.00      0.00      0.00        74\n",
      "         714       0.00      0.00      0.00       172\n",
      "         715       0.67      0.05      0.09        44\n",
      "         716       0.50      0.04      0.08        46\n",
      "         717       0.67      0.03      0.06        66\n",
      "         718       0.52      0.08      0.13       156\n",
      "         719       0.50      0.03      0.06        58\n",
      "         720       0.50      0.03      0.06        58\n",
      "         721       0.25      0.02      0.04        45\n",
      "         722       0.81      0.22      0.35       208\n",
      "         723       0.81      0.41      0.54       106\n",
      "         724       0.75      0.46      0.57        97\n",
      "         725       0.81      0.37      0.50       126\n",
      "         726       0.80      0.31      0.45       142\n",
      "         727       0.88      0.30      0.44        47\n",
      "         728       0.00      0.00      0.00        34\n",
      "         729       0.00      0.00      0.00        31\n",
      "         730       0.20      0.02      0.03        53\n",
      "         731       0.53      0.10      0.16        93\n",
      "         732       0.00      0.00      0.00        38\n",
      "         733       0.40      0.05      0.09        42\n",
      "         734       0.57      0.05      0.10        76\n",
      "         735       0.40      0.02      0.03       111\n",
      "         736       0.39      0.25      0.30        61\n",
      "         737       0.57      0.14      0.23        57\n",
      "         738       0.55      0.04      0.08       142\n",
      "         739       0.77      0.36      0.49        55\n",
      "         740       0.69      0.28      0.39       149\n",
      "         741       0.64      0.25      0.36       118\n",
      "         742       0.65      0.24      0.35        54\n",
      "         743       0.62      0.26      0.37        38\n",
      "         744       0.55      0.45      0.50        60\n",
      "         745       0.44      0.47      0.45        36\n",
      "         746       0.46      0.42      0.44        45\n",
      "         747       0.46      0.53      0.49        34\n",
      "         748       0.46      0.53      0.49        34\n",
      "         749       0.00      0.00      0.00        30\n",
      "         750       0.80      0.04      0.08        96\n",
      "         751       0.83      0.04      0.08       118\n",
      "         752       0.00      0.00      0.00        28\n",
      "         753       0.25      0.01      0.03       151\n",
      "         754       0.00      0.00      0.00        44\n",
      "         755       1.00      0.03      0.05        72\n",
      "         756       0.00      0.00      0.00        49\n",
      "         757       0.00      0.00      0.00        39\n",
      "         758       1.00      0.01      0.02        81\n",
      "         759       0.50      0.05      0.10        92\n",
      "         760       1.00      0.01      0.02        85\n",
      "         761       0.00      0.00      0.00        50\n",
      "         762       0.40      0.09      0.14        46\n",
      "         763       0.33      0.09      0.14        35\n",
      "         764       0.44      0.08      0.13        51\n",
      "         765       0.65      0.16      0.26       150\n",
      "         766       0.61      0.16      0.25       172\n",
      "         767       0.50      0.04      0.07        81\n",
      "         768       0.47      0.08      0.14       111\n",
      "         769       0.00      0.00      0.00       107\n",
      "         770       0.50      0.01      0.02       243\n",
      "         771       0.00      0.00      0.00        65\n",
      "         772       0.00      0.00      0.00        67\n",
      "         773       0.00      0.00      0.00        79\n",
      "         774       0.00      0.00      0.00        57\n",
      "         775       0.50      0.06      0.11        32\n",
      "         776       0.50      0.09      0.16        43\n",
      "         777       0.43      0.09      0.15        34\n",
      "         778       0.00      0.00      0.00        43\n",
      "         779       0.58      0.17      0.26        41\n",
      "         780       0.48      0.16      0.24        82\n",
      "         781       0.50      0.16      0.24        81\n",
      "         782       0.00      0.00      0.00        66\n",
      "         783       0.33      0.09      0.14        55\n",
      "         784       0.00      0.00      0.00        48\n",
      "         785       0.40      0.04      0.08        45\n",
      "         786       1.00      0.05      0.09        85\n",
      "         787       0.46      0.21      0.28       131\n",
      "         788       0.53      0.16      0.24        63\n",
      "         789       0.46      0.22      0.30       128\n",
      "         790       0.43      0.21      0.28       220\n",
      "         791       0.55      0.04      0.08       136\n",
      "         792       0.46      0.05      0.09       118\n",
      "         793       0.43      0.05      0.09       127\n",
      "         794       0.00      0.00      0.00        46\n",
      "         795       0.00      0.00      0.00        66\n",
      "         796       0.00      0.00      0.00        53\n",
      "         797       0.00      0.00      0.00       114\n",
      "         798       0.00      0.00      0.00        54\n",
      "         799       0.00      0.00      0.00       114\n",
      "         800       0.00      0.00      0.00        55\n",
      "         801       0.00      0.00      0.00        46\n",
      "         802       0.00      0.00      0.00        47\n",
      "         803       0.00      0.00      0.00        49\n",
      "         804       0.33      0.01      0.02        93\n",
      "         805       0.00      0.00      0.00        55\n",
      "         806       0.50      0.01      0.02       103\n",
      "         807       0.25      0.01      0.03        75\n",
      "         808       0.29      0.05      0.08        41\n",
      "         809       0.43      0.11      0.18        87\n",
      "         810       0.50      0.29      0.36        28\n",
      "         811       0.33      0.04      0.08        46\n",
      "         812       0.73      0.19      0.30        59\n",
      "         813       0.62      0.20      0.30        41\n",
      "         814       0.50      0.10      0.16        42\n",
      "         815       0.67      0.06      0.11        33\n",
      "         816       0.70      0.25      0.37        28\n",
      "         817       0.67      0.37      0.48        27\n",
      "         818       0.57      0.22      0.32        59\n",
      "         819       0.54      0.19      0.28        68\n",
      "         820       0.50      0.04      0.07        53\n",
      "         821       0.50      0.04      0.07        53\n",
      "         822       0.64      0.25      0.36        36\n",
      "         823       0.79      0.24      0.37        63\n",
      "         824       0.00      0.00      0.00        33\n",
      "         825       0.00      0.00      0.00       100\n",
      "         826       0.00      0.00      0.00        34\n",
      "         827       0.50      0.08      0.13        39\n",
      "         828       0.00      0.00      0.00        42\n",
      "         829       0.00      0.00      0.00        40\n",
      "         830       0.00      0.00      0.00        62\n",
      "         831       0.17      0.01      0.02       117\n",
      "         832       0.00      0.00      0.00        35\n",
      "         833       0.60      0.07      0.12        46\n",
      "         834       0.35      0.17      0.23        42\n",
      "         835       0.68      0.25      0.36       108\n",
      "         836       0.78      0.23      0.35        61\n",
      "         837       0.57      0.29      0.38        45\n",
      "         838       0.50      0.22      0.30        32\n",
      "         839       0.62      0.07      0.12        75\n",
      "         840       1.00      0.08      0.15        49\n",
      "         841       0.83      0.10      0.18        49\n",
      "         842       0.46      0.12      0.18        52\n",
      "         843       0.62      0.28      0.38        36\n",
      "         844       0.00      0.00      0.00        46\n",
      "         845       0.00      0.00      0.00        34\n",
      "         846       0.62      0.06      0.11        83\n",
      "         847       1.00      0.01      0.02       113\n",
      "         848       0.62      0.16      0.26        80\n",
      "         849       0.73      0.18      0.29       106\n",
      "         850       0.75      0.17      0.27        54\n",
      "         851       0.70      0.11      0.19        65\n",
      "         852       0.00      0.00      0.00        52\n",
      "         853       1.00      0.06      0.12        64\n",
      "         854       1.00      0.04      0.08        76\n",
      "         855       0.00      0.00      0.00        33\n",
      "         856       0.00      0.00      0.00        35\n",
      "         857       0.61      0.15      0.24       113\n",
      "         858       0.00      0.00      0.00        35\n",
      "         859       0.00      0.00      0.00        36\n",
      "         860       0.00      0.00      0.00        32\n",
      "         861       0.33      0.02      0.04        47\n",
      "         862       0.63      0.10      0.18       116\n",
      "         863       0.57      0.06      0.11       135\n",
      "         864       0.25      0.06      0.10        47\n",
      "         865       0.67      0.06      0.11        35\n",
      "         866       0.33      0.05      0.09        41\n",
      "         867       0.00      0.00      0.00        44\n",
      "         868       1.00      0.06      0.11        36\n",
      "         869       0.50      0.02      0.04        44\n",
      "         870       0.00      0.00      0.00        46\n",
      "         871       0.00      0.00      0.00        68\n",
      "         872       0.00      0.00      0.00        43\n",
      "         873       0.00      0.00      0.00        39\n",
      "         874       0.00      0.00      0.00        71\n",
      "         875       0.00      0.00      0.00        52\n",
      "         876       0.00      0.00      0.00        39\n",
      "         877       1.00      0.02      0.03        65\n",
      "         878       0.00      0.00      0.00        31\n",
      "         879       0.00      0.00      0.00        32\n",
      "         880       1.00      0.01      0.02       121\n",
      "         881       1.00      0.01      0.02       118\n",
      "         882       0.00      0.00      0.00        34\n",
      "         883       0.33      0.06      0.10        33\n",
      "         884       0.00      0.00      0.00        33\n",
      "         885       0.43      0.06      0.10        53\n",
      "         886       0.00      0.00      0.00        58\n",
      "         887       0.33      0.03      0.06        92\n",
      "         888       0.25      0.03      0.06        89\n",
      "         889       0.00      0.00      0.00        38\n",
      "         890       0.25      0.02      0.04       147\n",
      "         891       0.30      0.02      0.04       152\n",
      "         892       0.64      0.24      0.35        66\n",
      "         893       0.00      0.00      0.00        64\n",
      "         894       0.00      0.00      0.00        45\n",
      "         895       0.00      0.00      0.00        32\n",
      "         896       0.35      0.12      0.18        48\n",
      "         897       0.73      0.29      0.41        28\n",
      "         898       0.00      0.00      0.00        72\n",
      "         899       0.00      0.00      0.00        61\n",
      "         900       1.00      0.02      0.05        42\n",
      "         901       0.49      0.19      0.27       127\n",
      "         902       0.40      0.03      0.05        79\n",
      "         903       1.00      0.06      0.11        35\n",
      "         904       0.60      0.03      0.06        90\n",
      "         905       0.43      0.04      0.08        69\n",
      "         906       0.33      0.04      0.08        45\n",
      "         907       0.50      0.04      0.08        69\n",
      "         908       0.00      0.00      0.00        54\n",
      "         909       0.00      0.00      0.00        48\n",
      "         910       0.00      0.00      0.00        29\n",
      "         911       1.00      0.01      0.02        84\n",
      "         912       0.25      0.04      0.06        28\n",
      "         913       0.62      0.19      0.29        81\n",
      "         914       0.69      0.19      0.30        57\n",
      "         915       0.58      0.27      0.37       120\n",
      "         916       0.60      0.18      0.28        50\n",
      "         917       0.00      0.00      0.00        58\n",
      "         918       0.17      0.15      0.16        27\n",
      "         919       0.30      0.23      0.26        31\n",
      "         920       0.32      0.18      0.23        34\n",
      "         921       0.46      0.24      0.32        94\n",
      "         922       0.17      0.17      0.17        24\n",
      "         923       0.30      0.21      0.25        42\n",
      "         924       0.42      0.17      0.25        80\n",
      "         925       0.31      0.14      0.20        56\n",
      "         926       0.35      0.17      0.23        53\n",
      "         927       0.56      0.18      0.27       101\n",
      "         928       0.25      0.10      0.14        51\n",
      "         929       0.32      0.24      0.27        42\n",
      "         930       0.47      0.24      0.32        94\n",
      "         931       0.20      0.18      0.19        22\n",
      "         932       0.43      0.09      0.15        34\n",
      "         933       0.00      0.00      0.00        49\n",
      "         934       0.67      0.05      0.09        42\n",
      "         935       0.00      0.00      0.00        59\n",
      "         936       0.00      0.00      0.00        39\n",
      "         937       0.00      0.00      0.00        36\n",
      "         938       0.89      0.18      0.30        44\n",
      "         939       0.30      0.27      0.29        33\n",
      "         940       0.00      0.00      0.00        32\n",
      "         941       0.58      0.32      0.41        93\n",
      "         942       0.57      0.31      0.40       108\n",
      "         943       0.57      0.26      0.35        98\n",
      "         944       0.42      0.19      0.27        57\n",
      "         945       0.47      0.21      0.29        66\n",
      "         946       0.61      0.37      0.46        90\n",
      "         947       0.00      0.00      0.00        77\n",
      "         948       0.00      0.00      0.00        33\n",
      "         949       0.00      0.00      0.00        80\n",
      "         950       0.50      0.03      0.06        58\n",
      "         951       1.00      0.03      0.06        32\n",
      "         952       0.00      0.00      0.00        35\n",
      "         953       0.00      0.00      0.00        33\n",
      "         954       1.00      0.02      0.04        49\n",
      "         955       0.50      0.02      0.04        46\n",
      "         956       0.50      0.02      0.04        44\n",
      "         957       0.50      0.02      0.04        44\n",
      "         958       0.00      0.00      0.00        45\n",
      "         959       0.00      0.00      0.00        37\n",
      "         960       0.17      0.01      0.02        79\n",
      "         961       0.00      0.00      0.00        31\n",
      "         962       0.00      0.00      0.00        42\n",
      "         963       0.00      0.00      0.00        41\n",
      "         964       0.00      0.00      0.00        44\n",
      "         965       0.00      0.00      0.00        33\n",
      "         966       0.33      0.02      0.04        49\n",
      "         967       0.00      0.00      0.00        34\n",
      "         968       0.00      0.00      0.00        47\n",
      "         969       0.33      0.12      0.18        25\n",
      "         970       0.45      0.24      0.31        38\n",
      "         971       0.22      0.15      0.18        26\n",
      "         972       0.00      0.00      0.00        35\n",
      "         973       0.67      0.01      0.03       136\n",
      "         974       0.00      0.00      0.00        40\n",
      "         975       0.00      0.00      0.00        43\n",
      "         976       0.00      0.00      0.00        55\n",
      "         977       1.00      0.05      0.10        40\n",
      "         978       0.67      0.06      0.11        35\n",
      "         979       0.00      0.00      0.00        46\n",
      "         980       0.70      0.12      0.21        56\n",
      "         981       0.00      0.00      0.00        32\n",
      "         982       0.33      0.05      0.08        43\n",
      "         983       0.71      0.14      0.24       138\n",
      "         984       0.72      0.15      0.24       124\n",
      "         985       0.64      0.15      0.25       118\n",
      "         986       0.62      0.16      0.26        97\n",
      "         987       0.33      0.01      0.02        93\n",
      "         988       0.12      0.02      0.03        54\n",
      "         989       0.00      0.00      0.00        38\n",
      "         990       0.67      0.12      0.21        48\n",
      "         991       0.47      0.31      0.37        68\n",
      "         992       0.76      0.25      0.37        65\n",
      "         993       0.60      0.18      0.28        49\n",
      "         994       0.75      0.09      0.17        32\n",
      "         995       0.80      0.11      0.20        35\n",
      "         996       0.00      0.00      0.00        61\n",
      "         997       0.00      0.00      0.00        15\n",
      "         998       0.00      0.00      0.00        18\n",
      "         999       0.00      0.00      0.00        31\n",
      "        1000       1.00      0.05      0.10        40\n",
      "        1001       0.00      0.00      0.00        42\n",
      "        1002       0.67      0.06      0.11        69\n",
      "        1003       0.00      0.00      0.00        41\n",
      "        1004       0.62      0.26      0.37       107\n",
      "        1005       0.44      0.10      0.16        41\n",
      "        1006       0.71      0.27      0.39        83\n",
      "        1007       0.67      0.16      0.25        51\n",
      "        1008       0.67      0.19      0.29        43\n",
      "        1009       0.71      0.20      0.32        49\n",
      "        1010       0.50      0.01      0.03        68\n",
      "        1011       0.00      0.00      0.00        25\n",
      "        1012       0.00      0.00      0.00        34\n",
      "        1013       0.50      0.03      0.05        37\n",
      "        1014       0.71      0.08      0.14        62\n",
      "        1015       0.00      0.00      0.00        38\n",
      "        1016       0.00      0.00      0.00        55\n",
      "        1017       0.00      0.00      0.00        50\n",
      "        1018       0.60      0.18      0.27        34\n",
      "        1019       0.50      0.02      0.03        64\n",
      "        1020       0.50      0.02      0.03        62\n",
      "        1021       0.39      0.15      0.22        59\n",
      "        1022       0.00      0.00      0.00        39\n",
      "        1023       0.50      0.02      0.04        49\n",
      "        1024       0.50      0.03      0.05        36\n",
      "        1025       0.86      0.12      0.21        51\n",
      "        1026       0.50      0.02      0.03        64\n",
      "        1027       0.25      0.02      0.04        47\n",
      "        1028       0.25      0.01      0.02        81\n",
      "        1029       0.00      0.00      0.00        37\n",
      "        1030       0.00      0.00      0.00        37\n",
      "        1031       0.72      0.22      0.34        59\n",
      "        1032       1.00      0.02      0.05        42\n",
      "        1033       1.00      0.02      0.04        49\n",
      "        1034       0.67      0.07      0.13        27\n",
      "        1035       1.00      0.03      0.05        40\n",
      "        1036       0.45      0.11      0.18        46\n",
      "        1037       1.00      0.06      0.11        33\n",
      "        1038       0.33      0.03      0.06        94\n",
      "        1039       0.00      0.00      0.00        43\n",
      "        1040       0.40      0.07      0.12        27\n",
      "        1041       0.00      0.00      0.00        28\n",
      "        1042       0.00      0.00      0.00        32\n",
      "        1043       0.50      0.12      0.19        51\n",
      "        1044       0.45      0.11      0.18        45\n",
      "        1045       0.50      0.01      0.03        76\n",
      "        1046       0.35      0.12      0.18        56\n",
      "        1047       0.11      0.03      0.04        36\n",
      "        1048       0.17      0.03      0.05        34\n",
      "        1049       0.27      0.11      0.15        28\n",
      "        1050       0.40      0.09      0.15        65\n",
      "        1051       0.20      0.08      0.11        26\n",
      "        1052       0.29      0.09      0.13        47\n",
      "        1053       0.38      0.10      0.16        29\n",
      "        1054       0.00      0.00      0.00        26\n",
      "        1055       0.64      0.09      0.16        74\n",
      "        1056       0.00      0.00      0.00        68\n",
      "        1057       0.00      0.00      0.00        33\n",
      "        1058       0.00      0.00      0.00        44\n",
      "        1059       0.00      0.00      0.00        41\n",
      "        1060       0.17      0.19      0.18        21\n",
      "        1061       0.17      0.20      0.18        20\n",
      "        1062       0.00      0.00      0.00        34\n",
      "        1063       0.00      0.00      0.00        52\n",
      "        1064       0.00      0.00      0.00        40\n",
      "        1065       0.58      0.12      0.20        59\n",
      "        1066       0.14      0.03      0.05        34\n",
      "        1067       0.50      0.06      0.10        36\n",
      "        1068       0.00      0.00      0.00        34\n",
      "        1069       0.00      0.00      0.00        28\n",
      "        1070       0.50      0.02      0.04        47\n",
      "        1071       0.50      0.02      0.04        46\n",
      "        1072       0.00      0.00      0.00        48\n",
      "        1073       0.33      0.02      0.03        66\n",
      "        1074       0.25      0.01      0.03        72\n",
      "        1075       0.00      0.00      0.00        35\n",
      "        1076       0.00      0.00      0.00        65\n",
      "        1077       0.00      0.00      0.00        43\n",
      "        1078       0.00      0.00      0.00        36\n",
      "        1079       0.00      0.00      0.00        39\n",
      "        1080       0.00      0.00      0.00        53\n",
      "        1081       0.64      0.15      0.24        47\n",
      "        1082       0.00      0.00      0.00        37\n",
      "        1083       0.00      0.00      0.00        36\n",
      "        1084       0.38      0.11      0.17        46\n",
      "        1085       0.00      0.00      0.00        41\n",
      "        1086       1.00      0.03      0.06        34\n",
      "        1087       0.33      0.11      0.17        27\n",
      "        1088       0.29      0.07      0.11        29\n",
      "        1089       0.00      0.00      0.00        29\n",
      "        1090       0.71      0.15      0.25        33\n",
      "        1091       0.00      0.00      0.00        40\n",
      "        1092       0.50      0.02      0.04        51\n",
      "        1093       0.40      0.11      0.17        38\n",
      "        1094       0.00      0.00      0.00        47\n",
      "        1095       0.00      0.00      0.00        45\n",
      "        1096       0.00      0.00      0.00        42\n",
      "        1097       0.00      0.00      0.00        45\n",
      "\n",
      "   micro avg       0.61      0.29      0.40    221019\n",
      "   macro avg       0.40      0.12      0.16    221019\n",
      "weighted avg       0.52      0.29      0.34    221019\n",
      " samples avg       0.64      0.35      0.39    221019\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satria/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Convert probabilities to binary predictions\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 624us/step\n"
     ]
    }
   ],
   "source": [
    "### Prediction using sample test\n",
    "y_pred_gt = model.predict(X_test_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = generate_submission_df(y_pred_gt, test_ids, pred_columns)\n",
    "submission_df.to_csv('./dataset/prediction/sample_prediction_bp.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_pred_gt = post_processing(y_pred_gt, pred_columns, graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = generate_submission_df(new_y_pred_gt, test_ids, pred_columns)\n",
    "submission_df.to_csv('./dataset/prediction/sample_prediction_bp_propagate.tsv', sep='\\t', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non propagated predictions\n",
    "# File paths\n",
    "bp = './dataset/prediction/sample_prediction_bp.tsv'\n",
    "mf = './dataset/prediction/sample_prediction_mf.tsv'\n",
    "cc = './dataset/prediction/sample_prediction_cc.tsv'\n",
    "\n",
    "concat_df = concat_predictions(bp, mf, cc)\n",
    "\n",
    "# Output the result as a TSV file\n",
    "output_file = './dataset/prediction/sample_test_pred_all.tsv'\n",
    "concat_df.to_csv(output_file, sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate using CAFA Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cafaeval\n",
    "from cafaeval.evaluation import cafa_eval, write_results\n",
    "res = cafa_eval(\"./dataset/taxonomy/go-basic.obo\", \"./dataset/prediction/pred_all/\", \"./dataset/test/sampled_gt.tsv\")\n",
    "write_results(*res)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
