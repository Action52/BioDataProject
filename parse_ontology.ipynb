{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36fee129-afe6-4857-92c5-511826fe40da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import obonet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8fbb568e-b3e7-4d59-aaa4-b34b03175e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant\n",
    "TRAIN_DATASET_PATH = '../biological_data_pfp/train/train_set.tsv'\n",
    "GENE_ONTOLOGY_PATH = './dataset/taxonomy/go-basic.obo'\n",
    "RELATIONSHIP = {'is_a': 1, 'part_of': 0}\n",
    "N_LABELS = 1500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8cb8fe-8f8b-42b3-993a-1d617bbc980e",
   "metadata": {},
   "source": [
    "### Read the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8ec82535-df0c-4d4c-94a3-5430e62e3375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4278it [00:02, 1842.43it/s]                                                     \n"
     ]
    }
   ],
   "source": [
    "# Function to read a TSV file with a progress bar and concatenate into a single DataFrame\n",
    "def read_tsv_with_progress(filename):\n",
    "    # Count the number of lines (for the progress bar)\n",
    "    num_lines = sum(1 for line in open(filename, 'r'))\n",
    "    \n",
    "    # Create a tqdm object for the progress bar\n",
    "    tqdm_iterator = tqdm(pd.read_csv(filename, delimiter='\\t', chunksize=1000), total=num_lines/1000)\n",
    "    \n",
    "    # List to store each chunk\n",
    "    chunks = []\n",
    "\n",
    "    # Read the file in chunks and append each chunk to the list\n",
    "    for chunk in tqdm_iterator:\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    # Concatenate all chunks into a single DataFrame\n",
    "    df = pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Replace 'your_file.tsv' with the path to your TSV file\n",
    "main_df = read_tsv_with_progress(TRAIN_DATASET_PATH)\n",
    "\n",
    "cc_df = main_df[main_df['aspect'] == 'cellular_component']\n",
    "bp_df = main_df[main_df['aspect'] == 'biological_process']\n",
    "mf_df = main_df[main_df['aspect'] == 'molecular_function']\n",
    "\n",
    "cc_df = main_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fe8c451d-6a4a-436a-8503-1e5bde2fdeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satria/miniconda3/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame\n",
    "go_term_df = df[['GO_term']]  # Reshape to 2D array\n",
    "\n",
    "encoder = OneHotEncoder(sparse=True)  # Use sparse output\n",
    "encoder.fit(go_term_df)\n",
    "\n",
    "codes_sparse = encoder.transform(go_term_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c9a47-33fc-4e7e-81e5-01bd5e5ac1ec",
   "metadata": {},
   "source": [
    "### Read Gene Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "257936bb-d017-4826-a8c6-879c9d9f9f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.47 s, sys: 36.3 ms, total: 4.51 s\n",
      "Wall time: 4.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "graph = obonet.read_obo(GENE_ONTOLOGY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "06492ba9-994f-4fec-9af6-bad6728af147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42837"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "34d3b2f9-ac71-4e12-abb8-a1ab6a4ca713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83581"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "507ec976-ade4-4d4d-b305-d711d008a28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "networkx.is_directed_acyclic_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffaa77d-74d4-4632-bb3e-911351d64132",
   "metadata": {},
   "source": [
    "### Parse Node Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7e2c66f6-8aa0-43ae-86c6-16bc11391adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GO terms: 100%|████████████████| 678/678 [00:00<00:00, 102937.02it/s]\n",
      "Processing GO terms: 100%|█████████████████| 839/839 [00:00<00:00, 82135.68it/s]\n",
      "Processing GO terms: 100%|███████████████| 1487/1487 [00:00<00:00, 65461.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get pair relationship\n",
    "def generate_pairing(df, name):\n",
    "    pairing = {'child': [], 'relationship': [], 'parent': []}\n",
    "    GO_terms = df['GO_term'].copy().unique()\n",
    "    for term in tqdm(GO_terms, desc=\"Processing GO terms\"):\n",
    "        for parent, child, key in graph.in_edges(term, keys=True):\n",
    "            if key not in RELATIONSHIP:\n",
    "                continue\n",
    "    \n",
    "            pairing['child'].append(child)\n",
    "            pairing['relationship'].append(key)\n",
    "            pairing['parent'].append(parent)\n",
    "            \n",
    "    pairing_df = pd.DataFrame(pairing)\n",
    "    pairing_df.to_csv(f'./dataset/train/{name}_pairing.csv', index=False)\n",
    "\n",
    "for k, df in {'cellular_component': cc_df, 'biological_process': mf_df, 'molecullar_function': bp_df}.items():\n",
    "    generate_pairing(df, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "22d40441-ee3a-401a-9fc3-41a1d7d1ef72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing GO terms: 100%|███████| 1109632/1109632 [00:00<00:00, 4912211.72it/s]\n",
      "process sorting: 100%|███████████████████| 678/678 [00:00<00:00, 1275790.99it/s]\n",
      "Processing GO terms: 100%|█████████| 532532/532532 [00:00<00:00, 3990768.31it/s]\n",
      "process sorting: 100%|███████████████████| 839/839 [00:00<00:00, 3460197.70it/s]\n",
      "Processing GO terms: 100%|███████| 2634883/2634883 [00:00<00:00, 5150747.41it/s]\n",
      "process sorting: 100%|█████████████████| 1487/1487 [00:00<00:00, 4155183.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get frequency dictionary\n",
    "def generate_frequency(df, name):  \n",
    "    go_term_df = df[['GO_term']]\n",
    "    frequency = {}\n",
    "    for term in tqdm(go_term_df[\"GO_term\"], desc=\"Processing GO terms\"):\n",
    "        frequency.setdefault(term, 0)\n",
    "        frequency[term] += 1\n",
    "\n",
    "    freq_attributes = {'id': [], 'frequency': []}\n",
    "    # Sorted the value\n",
    "    for k, v in tqdm(sorted(frequency.items(), key=lambda item: item[1], reverse=True), desc=\"process sorting\"):\n",
    "        freq_attributes['id'].append(k)\n",
    "        freq_attributes['frequency'].append(v)\n",
    "        \n",
    "    freq_df = pd.DataFrame(freq_attributes)\n",
    "    freq_df.to_csv(f'./dataset/train/{name}_freq.csv', index=False)\n",
    "\n",
    "for k, df in {'cellular_component': cc_df, 'biological_process': mf_df, 'molecullar_function': bp_df}.items():\n",
    "    generate_frequency(df, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37a625c-47fc-4a92-8012-3b5516aaf2d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
